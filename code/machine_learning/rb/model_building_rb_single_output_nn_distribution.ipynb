{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Team</th>\n",
       "      <th>Fantasy Points</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Position Rank</th>\n",
       "      <th>Adjusted Passing Yards Projection</th>\n",
       "      <th>Adjusted Passing Touchdowns Projection</th>\n",
       "      <th>Adjusted Interceptions Projection</th>\n",
       "      <th>Adjusted Rushing Yards Projection</th>\n",
       "      <th>Adjusted Receiving Yards Projection</th>\n",
       "      <th>Adjusted Receptions Projection</th>\n",
       "      <th>Anytime Touchdown Probability</th>\n",
       "      <th>Location</th>\n",
       "      <th>Team Projected Score</th>\n",
       "      <th>Opponent Projected Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>christian mccaffrey</td>\n",
       "      <td>RB</td>\n",
       "      <td>CAR</td>\n",
       "      <td>26.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.512870</td>\n",
       "      <td>51.488656</td>\n",
       "      <td>6.544513</td>\n",
       "      <td>0.652778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>25.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>ezekiel elliott</td>\n",
       "      <td>RB</td>\n",
       "      <td>DAL</td>\n",
       "      <td>26.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.517442</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>3.574315</td>\n",
       "      <td>0.619772</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>dalvin cook</td>\n",
       "      <td>RB</td>\n",
       "      <td>MIN</td>\n",
       "      <td>17.3</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>3.544513</td>\n",
       "      <td>0.579832</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>21.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>josh jacobs</td>\n",
       "      <td>RB</td>\n",
       "      <td>LV</td>\n",
       "      <td>33.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>16.511344</td>\n",
       "      <td>2.477273</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>22.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>saquon barkley</td>\n",
       "      <td>RB</td>\n",
       "      <td>NYG</td>\n",
       "      <td>9.6</td>\n",
       "      <td>24.0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>3.471510</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>25.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>matt breida</td>\n",
       "      <td>RB</td>\n",
       "      <td>NYG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>latavius murray</td>\n",
       "      <td>RB</td>\n",
       "      <td>BUF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.25</td>\n",
       "      <td>12.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>trey sermon</td>\n",
       "      <td>RB</td>\n",
       "      <td>IND</td>\n",
       "      <td>5.1</td>\n",
       "      <td>228.0</td>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>19.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>deuce vaughn</td>\n",
       "      <td>RB</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1.7</td>\n",
       "      <td>254.0</td>\n",
       "      <td>77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.494463</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>lamical perine</td>\n",
       "      <td>RB</td>\n",
       "      <td>KC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.50</td>\n",
       "      <td>19.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4014 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  Week                 Name Position Team  Fantasy Points   Rank  \\\n",
       "0       2020     1  christian mccaffrey       RB  CAR            26.9    3.0   \n",
       "1       2020     1      ezekiel elliott       RB  DAL            26.2   16.0   \n",
       "2       2020     1          dalvin cook       RB  MIN            17.3   20.0   \n",
       "3       2020     1          josh jacobs       RB   LV            33.9   22.0   \n",
       "4       2020     1       saquon barkley       RB  NYG             9.6   24.0   \n",
       "...      ...   ...                  ...      ...  ...             ...    ...   \n",
       "4009    2023    17          matt breida       RB  NYG             0.0  207.0   \n",
       "4010    2023    17      latavius murray       RB  BUF             0.0  224.0   \n",
       "4011    2023    17          trey sermon       RB  IND             5.1  228.0   \n",
       "4012    2023    17         deuce vaughn       RB  DAL             1.7  254.0   \n",
       "4013    2023    17       lamical perine       RB   KC             0.0  279.0   \n",
       "\n",
       "      Position Rank  Adjusted Passing Yards Projection  \\\n",
       "0                 1                                NaN   \n",
       "1                 2                                NaN   \n",
       "2                 3                                NaN   \n",
       "3                 4                                NaN   \n",
       "4                 5                                NaN   \n",
       "...             ...                                ...   \n",
       "4009             63                                NaN   \n",
       "4010             65                                NaN   \n",
       "4011             67                                NaN   \n",
       "4012             77                                NaN   \n",
       "4013             84                                NaN   \n",
       "\n",
       "      Adjusted Passing Touchdowns Projection  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "4009                                     NaN   \n",
       "4010                                     NaN   \n",
       "4011                                     NaN   \n",
       "4012                                     NaN   \n",
       "4013                                     NaN   \n",
       "\n",
       "      Adjusted Interceptions Projection  Adjusted Rushing Yards Projection  \\\n",
       "0                                   NaN                          73.512870   \n",
       "1                                   NaN                          81.517442   \n",
       "2                                   NaN                          74.500000   \n",
       "3                                   NaN                          79.500000   \n",
       "4                                   NaN                          72.500000   \n",
       "...                                 ...                                ...   \n",
       "4009                                NaN                                NaN   \n",
       "4010                                NaN                                NaN   \n",
       "4011                                NaN                                NaN   \n",
       "4012                                NaN                           9.494463   \n",
       "4013                                NaN                                NaN   \n",
       "\n",
       "      Adjusted Receiving Yards Projection  Adjusted Receptions Projection  \\\n",
       "0                               51.488656                        6.544513   \n",
       "1                               29.500000                        3.574315   \n",
       "2                               28.500000                        3.544513   \n",
       "3                               16.511344                        2.477273   \n",
       "4                               33.500000                        3.471510   \n",
       "...                                   ...                             ...   \n",
       "4009                                  NaN                             NaN   \n",
       "4010                                  NaN                             NaN   \n",
       "4011                                  NaN                             NaN   \n",
       "4012                                  NaN                             NaN   \n",
       "4013                                  NaN                             NaN   \n",
       "\n",
       "      Anytime Touchdown Probability  Location  Team Projected Score  \\\n",
       "0                          0.652778       1.0                 22.50   \n",
       "1                          0.619772      -1.0                 25.50   \n",
       "2                          0.579832       1.0                 23.00   \n",
       "3                          0.607843      -1.0                 25.50   \n",
       "4                          0.523810       1.0                 19.00   \n",
       "...                             ...       ...                   ...   \n",
       "4009                       0.125000       1.0                 18.75   \n",
       "4010                       0.153846       1.0                 27.25   \n",
       "4011                       0.200000       1.0                 23.00   \n",
       "4012                       0.190476       1.0                 29.00   \n",
       "4013                       0.181818       1.0                 26.50   \n",
       "\n",
       "      Opponent Projected Score  \n",
       "0                        25.50  \n",
       "1                        26.50  \n",
       "2                        21.50  \n",
       "3                        22.50  \n",
       "4                        25.00  \n",
       "...                        ...  \n",
       "4009                     24.75  \n",
       "4010                     12.75  \n",
       "4011                     19.50  \n",
       "4012                     24.50  \n",
       "4013                     19.50  \n",
       "\n",
       "[4014 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "df_mod = pd.read_parquet('../../../data/model_data/model_data_single_output.parquet')\n",
    "\n",
    "df_mod = df_mod.loc[df_mod['Position'] == 'RB', :].reset_index(drop=True)\n",
    "\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Position Rank</th>\n",
       "      <th>Location</th>\n",
       "      <th>Team Projected Score</th>\n",
       "      <th>Opponent Projected Score</th>\n",
       "      <th>Adjusted Receptions Projection</th>\n",
       "      <th>Adjusted Receiving Yards Projection</th>\n",
       "      <th>Adjusted Rushing Yards Projection</th>\n",
       "      <th>Anytime Touchdown Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.50</td>\n",
       "      <td>25.50</td>\n",
       "      <td>6.544513</td>\n",
       "      <td>51.488656</td>\n",
       "      <td>73.512870</td>\n",
       "      <td>0.652778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>26.50</td>\n",
       "      <td>3.574315</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>81.517442</td>\n",
       "      <td>0.619772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>21.50</td>\n",
       "      <td>3.544513</td>\n",
       "      <td>28.500000</td>\n",
       "      <td>74.500000</td>\n",
       "      <td>0.579832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.50</td>\n",
       "      <td>22.50</td>\n",
       "      <td>2.477273</td>\n",
       "      <td>16.511344</td>\n",
       "      <td>79.500000</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>3.471510</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>72.500000</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>207.0</td>\n",
       "      <td>63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>24.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>224.0</td>\n",
       "      <td>65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.25</td>\n",
       "      <td>12.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>228.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>19.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>254.0</td>\n",
       "      <td>77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>24.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.494463</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>279.0</td>\n",
       "      <td>84</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.50</td>\n",
       "      <td>19.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4014 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rank  Position Rank  Location  Team Projected Score  \\\n",
       "0       3.0              1       1.0                 22.50   \n",
       "1      16.0              2      -1.0                 25.50   \n",
       "2      20.0              3       1.0                 23.00   \n",
       "3      22.0              4      -1.0                 25.50   \n",
       "4      24.0              5       1.0                 19.00   \n",
       "...     ...            ...       ...                   ...   \n",
       "4009  207.0             63       1.0                 18.75   \n",
       "4010  224.0             65       1.0                 27.25   \n",
       "4011  228.0             67       1.0                 23.00   \n",
       "4012  254.0             77       1.0                 29.00   \n",
       "4013  279.0             84       1.0                 26.50   \n",
       "\n",
       "      Opponent Projected Score  Adjusted Receptions Projection  \\\n",
       "0                        25.50                        6.544513   \n",
       "1                        26.50                        3.574315   \n",
       "2                        21.50                        3.544513   \n",
       "3                        22.50                        2.477273   \n",
       "4                        25.00                        3.471510   \n",
       "...                        ...                             ...   \n",
       "4009                     24.75                             NaN   \n",
       "4010                     12.75                             NaN   \n",
       "4011                     19.50                             NaN   \n",
       "4012                     24.50                             NaN   \n",
       "4013                     19.50                             NaN   \n",
       "\n",
       "      Adjusted Receiving Yards Projection  Adjusted Rushing Yards Projection  \\\n",
       "0                               51.488656                          73.512870   \n",
       "1                               29.500000                          81.517442   \n",
       "2                               28.500000                          74.500000   \n",
       "3                               16.511344                          79.500000   \n",
       "4                               33.500000                          72.500000   \n",
       "...                                   ...                                ...   \n",
       "4009                                  NaN                                NaN   \n",
       "4010                                  NaN                                NaN   \n",
       "4011                                  NaN                                NaN   \n",
       "4012                                  NaN                           9.494463   \n",
       "4013                                  NaN                                NaN   \n",
       "\n",
       "      Anytime Touchdown Probability  \n",
       "0                          0.652778  \n",
       "1                          0.619772  \n",
       "2                          0.579832  \n",
       "3                          0.607843  \n",
       "4                          0.523810  \n",
       "...                             ...  \n",
       "4009                       0.125000  \n",
       "4010                       0.153846  \n",
       "4011                       0.200000  \n",
       "4012                       0.190476  \n",
       "4013                       0.181818  \n",
       "\n",
       "[4014 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_mod[[\n",
    "    'Rank',\n",
    "    'Position Rank',\n",
    "    'Location',\n",
    "    'Team Projected Score',\n",
    "    'Opponent Projected Score',\n",
    "    'Adjusted Receptions Projection',\n",
    "    'Adjusted Receiving Yards Projection',\n",
    "    'Adjusted Rushing Yards Projection',\n",
    "    'Anytime Touchdown Probability',\n",
    "]].copy()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       27\n",
       "1       26\n",
       "2       17\n",
       "3       34\n",
       "4       10\n",
       "        ..\n",
       "4009     0\n",
       "4010     0\n",
       "4011     5\n",
       "4012     2\n",
       "4013     0\n",
       "Name: Fantasy Points, Length: 4014, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_rounded = df_mod['Fantasy Points'].round().astype(int)\n",
    "\n",
    "points_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4 Fantasy Points</th>\n",
       "      <th>-3 Fantasy Points</th>\n",
       "      <th>-2 Fantasy Points</th>\n",
       "      <th>-1 Fantasy Points</th>\n",
       "      <th>0 Fantasy Points</th>\n",
       "      <th>1 Fantasy Points</th>\n",
       "      <th>2 Fantasy Points</th>\n",
       "      <th>3 Fantasy Points</th>\n",
       "      <th>4 Fantasy Points</th>\n",
       "      <th>5 Fantasy Points</th>\n",
       "      <th>6 Fantasy Points</th>\n",
       "      <th>7 Fantasy Points</th>\n",
       "      <th>8 Fantasy Points</th>\n",
       "      <th>9 Fantasy Points</th>\n",
       "      <th>10 Fantasy Points</th>\n",
       "      <th>11 Fantasy Points</th>\n",
       "      <th>12 Fantasy Points</th>\n",
       "      <th>13 Fantasy Points</th>\n",
       "      <th>14 Fantasy Points</th>\n",
       "      <th>15 Fantasy Points</th>\n",
       "      <th>16 Fantasy Points</th>\n",
       "      <th>17 Fantasy Points</th>\n",
       "      <th>18 Fantasy Points</th>\n",
       "      <th>19 Fantasy Points</th>\n",
       "      <th>20 Fantasy Points</th>\n",
       "      <th>21 Fantasy Points</th>\n",
       "      <th>22 Fantasy Points</th>\n",
       "      <th>23 Fantasy Points</th>\n",
       "      <th>24 Fantasy Points</th>\n",
       "      <th>25 Fantasy Points</th>\n",
       "      <th>26 Fantasy Points</th>\n",
       "      <th>27 Fantasy Points</th>\n",
       "      <th>28 Fantasy Points</th>\n",
       "      <th>29 Fantasy Points</th>\n",
       "      <th>30 Fantasy Points</th>\n",
       "      <th>31 Fantasy Points</th>\n",
       "      <th>32 Fantasy Points</th>\n",
       "      <th>33 Fantasy Points</th>\n",
       "      <th>34 Fantasy Points</th>\n",
       "      <th>35 Fantasy Points</th>\n",
       "      <th>36 Fantasy Points</th>\n",
       "      <th>37 Fantasy Points</th>\n",
       "      <th>38 Fantasy Points</th>\n",
       "      <th>39 Fantasy Points</th>\n",
       "      <th>40 Fantasy Points</th>\n",
       "      <th>41 Fantasy Points</th>\n",
       "      <th>42 Fantasy Points</th>\n",
       "      <th>43 Fantasy Points</th>\n",
       "      <th>44 Fantasy Points</th>\n",
       "      <th>45 Fantasy Points</th>\n",
       "      <th>46 Fantasy Points</th>\n",
       "      <th>47 Fantasy Points</th>\n",
       "      <th>48 Fantasy Points</th>\n",
       "      <th>49 Fantasy Points</th>\n",
       "      <th>50 Fantasy Points</th>\n",
       "      <th>51 Fantasy Points</th>\n",
       "      <th>52 Fantasy Points</th>\n",
       "      <th>53 Fantasy Points</th>\n",
       "      <th>54 Fantasy Points</th>\n",
       "      <th>55 Fantasy Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4009</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4014 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -4 Fantasy Points  -3 Fantasy Points  -2 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      -1 Fantasy Points  0 Fantasy Points  1 Fantasy Points  2 Fantasy Points  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   0.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "4009                0.0               1.0               0.0               0.0   \n",
       "4010                0.0               1.0               0.0               0.0   \n",
       "4011                0.0               0.0               0.0               0.0   \n",
       "4012                0.0               0.0               0.0               1.0   \n",
       "4013                0.0               1.0               0.0               0.0   \n",
       "\n",
       "      3 Fantasy Points  4 Fantasy Points  5 Fantasy Points  6 Fantasy Points  \\\n",
       "0                  0.0               0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0               0.0   \n",
       "4                  0.0               0.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "4009               0.0               0.0               0.0               0.0   \n",
       "4010               0.0               0.0               0.0               0.0   \n",
       "4011               0.0               0.0               1.0               0.0   \n",
       "4012               0.0               0.0               0.0               0.0   \n",
       "4013               0.0               0.0               0.0               0.0   \n",
       "\n",
       "      7 Fantasy Points  8 Fantasy Points  9 Fantasy Points  10 Fantasy Points  \\\n",
       "0                  0.0               0.0               0.0                0.0   \n",
       "1                  0.0               0.0               0.0                0.0   \n",
       "2                  0.0               0.0               0.0                0.0   \n",
       "3                  0.0               0.0               0.0                0.0   \n",
       "4                  0.0               0.0               0.0                1.0   \n",
       "...                ...               ...               ...                ...   \n",
       "4009               0.0               0.0               0.0                0.0   \n",
       "4010               0.0               0.0               0.0                0.0   \n",
       "4011               0.0               0.0               0.0                0.0   \n",
       "4012               0.0               0.0               0.0                0.0   \n",
       "4013               0.0               0.0               0.0                0.0   \n",
       "\n",
       "      11 Fantasy Points  12 Fantasy Points  13 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      14 Fantasy Points  15 Fantasy Points  16 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      17 Fantasy Points  18 Fantasy Points  19 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   1.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      20 Fantasy Points  21 Fantasy Points  22 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      23 Fantasy Points  24 Fantasy Points  25 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      26 Fantasy Points  27 Fantasy Points  28 Fantasy Points  \\\n",
       "0                   0.0                1.0                0.0   \n",
       "1                   1.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      29 Fantasy Points  30 Fantasy Points  31 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      32 Fantasy Points  33 Fantasy Points  34 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                1.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      35 Fantasy Points  36 Fantasy Points  37 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      38 Fantasy Points  39 Fantasy Points  40 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      41 Fantasy Points  42 Fantasy Points  43 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      44 Fantasy Points  45 Fantasy Points  46 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      47 Fantasy Points  48 Fantasy Points  49 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      50 Fantasy Points  51 Fantasy Points  52 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "4009                0.0                0.0                0.0   \n",
       "4010                0.0                0.0                0.0   \n",
       "4011                0.0                0.0                0.0   \n",
       "4012                0.0                0.0                0.0   \n",
       "4013                0.0                0.0                0.0   \n",
       "\n",
       "      53 Fantasy Points  54 Fantasy Points  55 Fantasy Points  \n",
       "0                   0.0                0.0                0.0  \n",
       "1                   0.0                0.0                0.0  \n",
       "2                   0.0                0.0                0.0  \n",
       "3                   0.0                0.0                0.0  \n",
       "4                   0.0                0.0                0.0  \n",
       "...                 ...                ...                ...  \n",
       "4009                0.0                0.0                0.0  \n",
       "4010                0.0                0.0                0.0  \n",
       "4011                0.0                0.0                0.0  \n",
       "4012                0.0                0.0                0.0  \n",
       "4013                0.0                0.0                0.0  \n",
       "\n",
       "[4014 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# first column: -5 points scored\n",
    "# last column: 55 points scored\n",
    "y = np.zeros(shape=(points_rounded.shape[0], 60))\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    y[i, points_rounded.iloc[i] + 4] = 1\n",
    "\n",
    "y = pd.DataFrame(\n",
    "    y,\n",
    "    columns=[f\"{i - 4} Fantasy Points\" for i in range(y.shape[1])]\n",
    ")\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2020 Week 1\n",
       "1        2020 Week 1\n",
       "2        2020 Week 1\n",
       "3        2020 Week 1\n",
       "4        2020 Week 1\n",
       "            ...     \n",
       "4009    2023 Week 17\n",
       "4010    2023 Week 17\n",
       "4011    2023 Week 17\n",
       "4012    2023 Week 17\n",
       "4013    2023 Week 17\n",
       "Length: 4014, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = df_mod['Season'].astype(str) + ' Week ' + df_mod['Week'].astype(str)\n",
    "\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold ID</th>\n",
       "      <th>Season Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022 Week 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023 Week 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>2020 Week 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>2023 Week 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>2021 Week 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>2022 Week 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>2022 Week 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fold ID   Season Week\n",
       "0         0   2022 Week 3\n",
       "1         0   2021 Week 7\n",
       "2         0   2021 Week 1\n",
       "3         0  2023 Week 16\n",
       "4         0  2021 Week 11\n",
       "..      ...           ...\n",
       "62        2  2020 Week 15\n",
       "63        2  2023 Week 14\n",
       "64        2   2021 Week 5\n",
       "65        2   2022 Week 6\n",
       "66        2  2022 Week 12\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds = pd.read_parquet('../../../data/model_data/folds.parquet')\n",
    "\n",
    "df_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2199, 6) (430, 6) (1385, 6) (2199, 60) (430, 60) (1385, 60) (1385, 18)\n",
      "(2303, 6) (423, 6) (1288, 6) (2303, 60) (423, 60) (1288, 60) (1288, 18)\n",
      "(2266, 6) (407, 6) (1341, 6) (2266, 60) (407, 60) (1341, 60) (1341, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# splitter = GroupKFold(n_splits=3)\n",
    "\n",
    "cv_data = []\n",
    "# for is_indexes, oos_indexes in splitter.split(X=X, y=y, groups=groups):\n",
    "for fold in df_folds['Fold ID'].unique():\n",
    "    oos_season_week = df_folds.loc[df_folds['Fold ID'] == fold, 'Season Week']\n",
    "    is_indexes = df_mod.loc[~groups.isin(oos_season_week), :].index\n",
    "    oos_indexes = df_mod.loc[groups.isin(oos_season_week), :].index\n",
    "    # split\n",
    "    X_is = X.iloc[is_indexes]\n",
    "    X_oos = X.iloc[oos_indexes]\n",
    "\n",
    "    y_is = y.iloc[is_indexes]\n",
    "    y_oos = y.iloc[oos_indexes]\n",
    "\n",
    "    groups_is = groups.iloc[is_indexes]\n",
    "    df_mod_oos = df_mod.iloc[oos_indexes]\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=22)\n",
    "    for train_indexes, val_indexes in gss.split(X=X_is, y=y_is, groups=groups_is):\n",
    "            X_train = X_is.iloc[train_indexes]\n",
    "            X_val = X_is.iloc[val_indexes]\n",
    "\n",
    "            y_train = y_is.iloc[train_indexes]\n",
    "            y_val = y_is.iloc[val_indexes]\n",
    "\n",
    "    # impute\n",
    "    scaler = StandardScaler()\n",
    "    imputer = IterativeImputer(initial_strategy='median', max_iter=100)\n",
    "\n",
    "    X_train_fill_na = imputer.fit_transform(scaler.fit_transform(X_train))\n",
    "    X_train[X_train.columns] = scaler.inverse_transform(X_train_fill_na).copy()\n",
    "    X_train['Prop Bets Projection'] = (\n",
    "        X_train['Adjusted Receiving Yards Projection']*0.1 + \n",
    "        X_train['Adjusted Receptions Projection']*0.5 + \n",
    "        X_train['Adjusted Rushing Yards Projection']*0.1 +\n",
    "        X_train['Anytime Touchdown Probability']*6\n",
    "    )\n",
    "\n",
    "    scaler2 = MinMaxScaler(clip=True)  # maybe normalize and clip instead of standardize?\n",
    "    scaler3 = StandardScaler()\n",
    "    X_train[X_train.columns] = scaler3.fit_transform(scaler2.fit_transform(X_train)).copy()\n",
    "\n",
    "    X_val_fill_na = imputer.transform(scaler.transform(X_val))\n",
    "    X_val[X_val.columns] = scaler.inverse_transform(X_val_fill_na).copy()\n",
    "    X_val['Prop Bets Projection'] = (\n",
    "        X_val['Adjusted Receiving Yards Projection']*0.1 + \n",
    "        X_val['Adjusted Receptions Projection']*0.5 + \n",
    "        X_val['Adjusted Rushing Yards Projection']*0.1 +\n",
    "        X_val['Anytime Touchdown Probability']*6\n",
    "    )\n",
    "\n",
    "    X_val[X_val.columns] = scaler3.transform(scaler2.transform(X_val)).copy()\n",
    "\n",
    "    X_oos_fill_na = imputer.transform(scaler.transform(X_oos))\n",
    "    X_oos[X_oos.columns] = scaler.inverse_transform(X_oos_fill_na).copy()\n",
    "    X_oos['Prop Bets Projection'] = (\n",
    "        X_oos['Adjusted Receiving Yards Projection']*0.1 + \n",
    "        X_oos['Adjusted Receptions Projection']*0.5 + \n",
    "        X_oos['Adjusted Rushing Yards Projection']*0.1 +\n",
    "        X_oos['Anytime Touchdown Probability']*6\n",
    "    )\n",
    "\n",
    "    X_oos[X_oos.columns] = scaler3.transform(scaler2.transform(X_oos)).copy()\n",
    "\n",
    "    X_train.drop(columns=['Adjusted Receiving Yards Projection', 'Adjusted Receptions Projection', 'Adjusted Rushing Yards Projection', 'Anytime Touchdown Probability'], inplace=True)\n",
    "    X_val.drop(columns=['Adjusted Receiving Yards Projection', 'Adjusted Receptions Projection', 'Adjusted Rushing Yards Projection', 'Anytime Touchdown Probability'], inplace=True)\n",
    "    X_oos.drop(columns=['Adjusted Receiving Yards Projection', 'Adjusted Receptions Projection', 'Adjusted Rushing Yards Projection', 'Anytime Touchdown Probability'], inplace=True)\n",
    "\n",
    "    cv_data.append((X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos))\n",
    "\n",
    "for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "    print(X_train.shape, X_val.shape, X_oos.shape, y_train.shape, y_val.shape, y_oos.shape, df_mod_oos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 9)]               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 128)               1280      \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 60)                1980      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,388\n",
      "Trainable params: 7,388\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.config.experimental import enable_op_determinism\n",
    "from tensorflow.random import set_seed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "def build_and_compile_model(input_shape: tuple, output_shape: int, hidden_layer_neurons: list, l1s: list, l2s: list, learning_rate: float):\n",
    "    enable_op_determinism()\n",
    "    set_seed(22)\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "    h = inputs\n",
    "    for i, neurons in enumerate(hidden_layer_neurons):\n",
    "        h = Dense(\n",
    "            neurons, \n",
    "            activation='relu', \n",
    "            kernel_initializer=GlorotNormal(seed=22), \n",
    "            kernel_regularizer=L1L2(l1=l1s[i], l2=l2s[i]), \n",
    "            name=f\"hidden_{i+1}\"\n",
    "        )(h)\n",
    "\n",
    "    outputs = Dense(output_shape, activation='softmax', kernel_initializer=GlorotNormal(seed=22), name='outputs')(h)\n",
    "\n",
    "    mod = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    mod.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return mod\n",
    "\n",
    "mod = build_and_compile_model(X.shape[1:], y.shape[1], [128, 32], [0, 0.01], [0, 0.01], learning_rate=0.001)\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhugh\\anaconda3\\envs\\clean2\\lib\\site-packages\\optuna\\_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-10-21 16:41:16,109] A new study created in memory with name: no-name-fa4b45a0-8ade-4fcb-8938-19e616d79ddb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7d3b1ce2624fa2aea3f2354a2724ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:41:32,567] Trial 0 finished with value: 3.0411831510021647 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.022040451663772567, 'hidden_layer_1_l2': 0.08119509205386867, 'learning_rate': 0.01094741868844976, 'batch_size': 2048}. Best is trial 0 with value: 3.0411831510021647.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:41:41,688] Trial 1 finished with value: 3.2527118979789655 and parameters: {'n_hidden_layers': 3, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.058428964315689495, 'hidden_layer_1_l2': 0.07026355188654519, 'hidden_layer_2_neurons': 128, 'hidden_layer_2_l1': 0.08749277452777171, 'hidden_layer_2_l2': 0.07449320773686179, 'hidden_layer_3_neurons': 256, 'hidden_layer_3_l1': 0.009588460991804116, 'hidden_layer_3_l2': 0.004521011190769353, 'learning_rate': 0.07163458468004151, 'batch_size': 1024}. Best is trial 0 with value: 3.0411831510021647.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:41:54,290] Trial 2 finished with value: 3.047080696167433 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 64, 'hidden_layer_1_l1': 0.09115369973853776, 'hidden_layer_1_l2': 0.008625567976924198, 'hidden_layer_2_neurons': 2048, 'hidden_layer_2_l1': 0.0005512411903590642, 'hidden_layer_2_l2': 0.03576431697413079, 'learning_rate': 0.09578334240413691, 'batch_size': 1024}. Best is trial 0 with value: 3.0411831510021647.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:42:06,111] Trial 3 finished with value: 3.0479058422885323 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 1024, 'hidden_layer_1_l1': 0.08620878124622662, 'hidden_layer_1_l2': 0.06351961895274903, 'learning_rate': 0.07275008619568284, 'batch_size': 4096}. Best is trial 0 with value: 3.0411831510021647.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:42:16,524] Trial 4 finished with value: 3.0406090775640564 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 1024, 'hidden_layer_1_l1': 0.02024276263846314, 'hidden_layer_1_l2': 0.08721894394962987, 'learning_rate': 0.06424371980220045, 'batch_size': 1024}. Best is trial 4 with value: 3.0406090775640564.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:42:31,074] Trial 5 finished with value: 3.0256643882389005 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.05653980354893057, 'hidden_layer_1_l2': 0.00345150171194456, 'learning_rate': 0.0885147769978044, 'batch_size': 16384}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:42:40,797] Trial 6 finished with value: 3.25587926861729 and parameters: {'n_hidden_layers': 3, 'hidden_layer_1_neurons': 256, 'hidden_layer_1_l1': 0.07564442330254927, 'hidden_layer_1_l2': 0.045177882434907994, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.08362472880832089, 'hidden_layer_2_l2': 0.05103829122196473, 'hidden_layer_3_neurons': 128, 'hidden_layer_3_l1': 0.06951388599043494, 'hidden_layer_3_l2': 0.0051964104142108065, 'learning_rate': 0.09447015559422758, 'batch_size': 2048}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:42:52,121] Trial 7 finished with value: 3.032334539915451 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.08592805490779229, 'hidden_layer_1_l2': 0.0407904418229531, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.025309932195697216, 'hidden_layer_2_l2': 0.03508986025005804, 'learning_rate': 0.06905762708317247, 'batch_size': 1024}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:43:00,650] Trial 8 finished with value: 3.0384785314115073 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.004671699281628905, 'hidden_layer_1_l2': 0.056923526796298245, 'learning_rate': 0.09827798409489276, 'batch_size': 1024}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:43:11,846] Trial 9 finished with value: 3.046742311209619 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 256, 'hidden_layer_1_l1': 0.0004424057058423636, 'hidden_layer_1_l2': 0.06813144847420316, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.08249019408071431, 'hidden_layer_2_l2': 0.04359087388902699, 'learning_rate': 0.05221946484311475, 'batch_size': 1024}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:43:25,035] Trial 10 finished with value: 3.0287540042499623 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 64, 'hidden_layer_1_l1': 0.0438857733187344, 'hidden_layer_1_l2': 0.020597922809688127, 'learning_rate': 0.09085419387539485, 'batch_size': 16384}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:43:38,926] Trial 11 finished with value: 3.0268961535144925 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.05913861505258375, 'hidden_layer_1_l2': 0.02602769000457221, 'learning_rate': 0.0879967663964515, 'batch_size': 16384}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:43:53,170] Trial 12 finished with value: 3.0295571953283726 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.06675374325568896, 'hidden_layer_1_l2': 0.020543289898052295, 'learning_rate': 0.07029089849471185, 'batch_size': 16384}. Best is trial 5 with value: 3.0256643882389005.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:44:10,155] Trial 13 finished with value: 3.0197724843457023 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.024780931300023186, 'hidden_layer_1_l2': 0.007604881829401252, 'learning_rate': 0.03915445220504106, 'batch_size': 16384}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:44:33,220] Trial 14 finished with value: 3.022640995635421 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 64, 'hidden_layer_1_l1': 0.02571771086591236, 'hidden_layer_1_l2': 0.011879878323734515, 'learning_rate': 0.02355468003349173, 'batch_size': 16384}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:44:50,349] Trial 15 finished with value: 3.0222328575337736 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.010125863088279636, 'hidden_layer_1_l2': 0.009165707727317925, 'learning_rate': 0.03013753719152669, 'batch_size': 16384}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:45:00,419] Trial 16 finished with value: 3.0510359107533267 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.0004461934316414666, 'hidden_layer_1_l2': 0.005397864829105569, 'learning_rate': 0.05349399610470376, 'batch_size': 16384}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:45:15,834] Trial 17 finished with value: 3.2467670292838964 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.02514192028774061, 'hidden_layer_1_l2': 0.013961377455686059, 'hidden_layer_2_neurons': 32, 'hidden_layer_2_l1': 0.05651239531431575, 'hidden_layer_2_l2': 0.002132458116708126, 'learning_rate': 0.020525945059592425, 'batch_size': 2048}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:45:40,374] Trial 18 finished with value: 3.0362249908335923 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 512, 'hidden_layer_1_l1': 0.06117488006344264, 'hidden_layer_1_l2': 0.045743968564776, 'learning_rate': 0.012684496291830449, 'batch_size': 16384}. Best is trial 13 with value: 3.0197724843457023.\n",
      "(4014, 60) (4014, 60)\n",
      "[I 2024-10-21 16:45:52,735] Trial 19 finished with value: 3.035301732092472 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 512, 'hidden_layer_1_l1': 0.012134858697010104, 'hidden_layer_1_l2': 0.0021153037955230726, 'learning_rate': 0.032701077254611806, 'batch_size': 1024}. Best is trial 13 with value: 3.0197724843457023.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_hidden_layers': 1,\n",
       " 'hidden_layer_1_neurons': 32,\n",
       " 'hidden_layer_1_l1': 0.024780931300023186,\n",
       " 'hidden_layer_1_l2': 0.007604881829401252,\n",
       " 'learning_rate': 0.03915445220504106,\n",
       " 'batch_size': 16384}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import optuna\n",
    "\n",
    "def objective(trial, cv_data=cv_data):\n",
    "# model tuning\n",
    "    n_hidden_layers = trial.suggest_int(f\"n_hidden_layers\", 1, 3)\n",
    "\n",
    "    hidden_layer_neurons = []\n",
    "    l1s = []\n",
    "    l2s = []\n",
    "    for i in range(n_hidden_layers):\n",
    "        hidden_layer_neurons.append(trial.suggest_categorical(f\"hidden_layer_{i+1}_neurons\", [2**n for n in range(5, 12)]))  # change to (3, 12)\n",
    "        # hidden_layer_neurons.append(trial.suggest_categorical(f\"hidden_layer_{i+1}_neurons\", [2**n for n in range(4, 9)]))  # bump this up\n",
    "        l1s.append(trial.suggest_float(f\"hidden_layer_{i+1}_l1\", 0.0, 0.1))  # change to (0.0, 0.05)\n",
    "        l2s.append(trial.suggest_float(f\"hidden_layer_{i+1}_l2\", 0.0, 0.1))  # change to (0.0, 0.20)\n",
    "\n",
    "    learning_rate = trial.suggest_float(f\"learning_rate\", 0.01, 0.10)\n",
    "    batch_size = trial.suggest_categorical(f\"batch_size\", [2**n for n in range(10, 16)])\n",
    "    # batch_size = trial.suggest_categorical(f\"batch_size\", [2**n for n in range(4, 12)])  # bump this up\n",
    "\n",
    "    # cross validation\n",
    "    y_oos_list = []\n",
    "    y_pred_list = []\n",
    "    for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "        # make sure to build mod in loop to prevent history\n",
    "        mod = build_and_compile_model(X_train.shape[1:], y_train.shape[1], hidden_layer_neurons, l1s, l2s, learning_rate)\n",
    "\n",
    "        mod.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=batch_size,\n",
    "            epochs=500,\n",
    "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        y_oos_list.append(y_oos)\n",
    "        y_pred_list.append(mod.predict(X_oos, verbose=0))\n",
    "\n",
    "\n",
    "    y_oos_concat = np.vstack(y_oos_list)\n",
    "    y_pred_concat = np.vstack(y_pred_list)\n",
    "\n",
    "    print(y_oos_concat.shape, y_pred_concat.shape)\n",
    "\n",
    "    return log_loss(y_oos_concat, y_pred_concat)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=22, n_startup_trials=10, multivariate=True, warn_independent_sampling=False))\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0197724843457023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.0410 - accuracy: 0.0255 - val_loss: 4.5555 - val_accuracy: 0.0628\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.5421 - accuracy: 0.0618 - val_loss: 4.2136 - val_accuracy: 0.0651\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 4.1877 - accuracy: 0.0728 - val_loss: 3.9572 - val_accuracy: 0.0744\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.9191 - accuracy: 0.0809 - val_loss: 3.7706 - val_accuracy: 0.0814\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.7190 - accuracy: 0.0882 - val_loss: 3.6233 - val_accuracy: 0.1093\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.5575 - accuracy: 0.1023 - val_loss: 3.5286 - val_accuracy: 0.1023\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.4514 - accuracy: 0.1073 - val_loss: 3.4666 - val_accuracy: 0.1093\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.3818 - accuracy: 0.1082 - val_loss: 3.4247 - val_accuracy: 0.1000\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3338 - accuracy: 0.1091 - val_loss: 3.3898 - val_accuracy: 0.1000\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2977 - accuracy: 0.1187 - val_loss: 3.3578 - val_accuracy: 0.1140\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2708 - accuracy: 0.1173 - val_loss: 3.3283 - val_accuracy: 0.1093\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2493 - accuracy: 0.1091 - val_loss: 3.3013 - val_accuracy: 0.1070\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.2299 - accuracy: 0.1019 - val_loss: 3.2792 - val_accuracy: 0.0977\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2131 - accuracy: 0.0991 - val_loss: 3.2692 - val_accuracy: 0.1163\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2057 - accuracy: 0.0991 - val_loss: 3.2608 - val_accuracy: 0.0907\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1974 - accuracy: 0.1028 - val_loss: 3.2522 - val_accuracy: 0.0977\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1878 - accuracy: 0.1101 - val_loss: 3.2427 - val_accuracy: 0.0953\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1757 - accuracy: 0.1123 - val_loss: 3.2374 - val_accuracy: 0.0977\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.1668 - accuracy: 0.1160 - val_loss: 3.2279 - val_accuracy: 0.1093\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1550 - accuracy: 0.1169 - val_loss: 3.2158 - val_accuracy: 0.0977\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1421 - accuracy: 0.1128 - val_loss: 3.2031 - val_accuracy: 0.0907\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 3.1307 - accuracy: 0.1151 - val_loss: 3.1918 - val_accuracy: 0.0930\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1226 - accuracy: 0.1123 - val_loss: 3.1832 - val_accuracy: 0.0977\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.1173 - accuracy: 0.1137 - val_loss: 3.1717 - val_accuracy: 0.1070\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.1085 - accuracy: 0.1182 - val_loss: 3.1611 - val_accuracy: 0.1023\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0996 - accuracy: 0.1191 - val_loss: 3.1559 - val_accuracy: 0.1023\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.0952 - accuracy: 0.1205 - val_loss: 3.1519 - val_accuracy: 0.1000\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 3.0915 - accuracy: 0.1191 - val_loss: 3.1464 - val_accuracy: 0.0977\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 3.0874 - accuracy: 0.1191 - val_loss: 3.1384 - val_accuracy: 0.0930\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0814 - accuracy: 0.1187 - val_loss: 3.1314 - val_accuracy: 0.0953\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0768 - accuracy: 0.1178 - val_loss: 3.1257 - val_accuracy: 0.0907\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0729 - accuracy: 0.1173 - val_loss: 3.1232 - val_accuracy: 0.0953\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0713 - accuracy: 0.1182 - val_loss: 3.1209 - val_accuracy: 0.0930\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0688 - accuracy: 0.1155 - val_loss: 3.1209 - val_accuracy: 0.0884\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0672 - accuracy: 0.1137 - val_loss: 3.1198 - val_accuracy: 0.0930\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0638 - accuracy: 0.1137 - val_loss: 3.1190 - val_accuracy: 0.0930\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0605 - accuracy: 0.1141 - val_loss: 3.1192 - val_accuracy: 0.0907\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0593 - accuracy: 0.1119 - val_loss: 3.1194 - val_accuracy: 0.0953\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0584 - accuracy: 0.1114 - val_loss: 3.1181 - val_accuracy: 0.0930\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0566 - accuracy: 0.1141 - val_loss: 3.1155 - val_accuracy: 0.0884\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0537 - accuracy: 0.1160 - val_loss: 3.1122 - val_accuracy: 0.0907\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.0494 - accuracy: 0.1146 - val_loss: 3.1135 - val_accuracy: 0.0907\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.0495 - accuracy: 0.1151 - val_loss: 3.1129 - val_accuracy: 0.0907\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0481 - accuracy: 0.1178 - val_loss: 3.1138 - val_accuracy: 0.0977\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0485 - accuracy: 0.1173 - val_loss: 3.1145 - val_accuracy: 0.0930\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0492 - accuracy: 0.1187 - val_loss: 3.1098 - val_accuracy: 0.0953\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0445 - accuracy: 0.1205 - val_loss: 3.1092 - val_accuracy: 0.0953\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0433 - accuracy: 0.1155 - val_loss: 3.1096 - val_accuracy: 0.0977\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0432 - accuracy: 0.1146 - val_loss: 3.1121 - val_accuracy: 0.0977\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0449 - accuracy: 0.1128 - val_loss: 3.1101 - val_accuracy: 0.0953\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0431 - accuracy: 0.1128 - val_loss: 3.1067 - val_accuracy: 0.0977\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0408 - accuracy: 0.1155 - val_loss: 3.1056 - val_accuracy: 0.1000\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0408 - accuracy: 0.1137 - val_loss: 3.1044 - val_accuracy: 0.0977\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0404 - accuracy: 0.1132 - val_loss: 3.1033 - val_accuracy: 0.0884\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0393 - accuracy: 0.1151 - val_loss: 3.1041 - val_accuracy: 0.0884\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0398 - accuracy: 0.1146 - val_loss: 3.1020 - val_accuracy: 0.0907\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.0375 - accuracy: 0.1169 - val_loss: 3.1001 - val_accuracy: 0.0953\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0366 - accuracy: 0.1178 - val_loss: 3.0995 - val_accuracy: 0.1000\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.0372 - accuracy: 0.1169 - val_loss: 3.0984 - val_accuracy: 0.0977\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0368 - accuracy: 0.1173 - val_loss: 3.0973 - val_accuracy: 0.0977\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0360 - accuracy: 0.1151 - val_loss: 3.0957 - val_accuracy: 0.0953\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0350 - accuracy: 0.1141 - val_loss: 3.0929 - val_accuracy: 0.0977\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.0335 - accuracy: 0.1164 - val_loss: 3.0946 - val_accuracy: 0.0953\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.0350 - accuracy: 0.1160 - val_loss: 3.0959 - val_accuracy: 0.1000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0342 - accuracy: 0.1137 - val_loss: 3.0959 - val_accuracy: 0.1000\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0324 - accuracy: 0.1155 - val_loss: 3.0947 - val_accuracy: 0.0953\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0314 - accuracy: 0.1173 - val_loss: 3.0937 - val_accuracy: 0.0953\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0320 - accuracy: 0.1169 - val_loss: 3.0932 - val_accuracy: 0.0977\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0322 - accuracy: 0.1155 - val_loss: 3.0933 - val_accuracy: 0.0977\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 3.0324 - accuracy: 0.1146 - val_loss: 3.0941 - val_accuracy: 0.0977\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0323 - accuracy: 0.1160 - val_loss: 3.0934 - val_accuracy: 0.1000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0313 - accuracy: 0.1160 - val_loss: 3.0929 - val_accuracy: 0.1000\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 868ms/step - loss: 5.0264 - accuracy: 0.0248 - val_loss: 4.5628 - val_accuracy: 0.0496\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 4.5338 - accuracy: 0.0569 - val_loss: 4.2135 - val_accuracy: 0.0567\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.1818 - accuracy: 0.0647 - val_loss: 3.9491 - val_accuracy: 0.0591\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9155 - accuracy: 0.0721 - val_loss: 3.7541 - val_accuracy: 0.0757\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.7201 - accuracy: 0.0764 - val_loss: 3.5957 - val_accuracy: 0.0969\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.5606 - accuracy: 0.1068 - val_loss: 3.4914 - val_accuracy: 0.1064\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.4550 - accuracy: 0.1133 - val_loss: 3.4212 - val_accuracy: 0.1087\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 3.3831 - accuracy: 0.1125 - val_loss: 3.3769 - val_accuracy: 0.1040\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.3368 - accuracy: 0.1133 - val_loss: 3.3442 - val_accuracy: 0.0946\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.3038 - accuracy: 0.1142 - val_loss: 3.3169 - val_accuracy: 0.0993\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 3.2758 - accuracy: 0.1086 - val_loss: 3.2961 - val_accuracy: 0.0993\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2524 - accuracy: 0.1042 - val_loss: 3.2764 - val_accuracy: 0.1064\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2285 - accuracy: 0.1020 - val_loss: 3.2666 - val_accuracy: 0.0993\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 3.2135 - accuracy: 0.0994 - val_loss: 3.2659 - val_accuracy: 0.1064\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.2066 - accuracy: 0.1129 - val_loss: 3.2663 - val_accuracy: 0.0993\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2023 - accuracy: 0.1107 - val_loss: 3.2613 - val_accuracy: 0.1017\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1942 - accuracy: 0.1168 - val_loss: 3.2491 - val_accuracy: 0.0969\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1809 - accuracy: 0.1125 - val_loss: 3.2374 - val_accuracy: 0.1135\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1682 - accuracy: 0.1164 - val_loss: 3.2295 - val_accuracy: 0.1064\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1580 - accuracy: 0.1172 - val_loss: 3.2222 - val_accuracy: 0.1017\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.1456 - accuracy: 0.1185 - val_loss: 3.2183 - val_accuracy: 0.1040\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1367 - accuracy: 0.1185 - val_loss: 3.2163 - val_accuracy: 0.1040\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 3.1314 - accuracy: 0.1181 - val_loss: 3.2106 - val_accuracy: 0.1017\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 3.1248 - accuracy: 0.1159 - val_loss: 3.2016 - val_accuracy: 0.0969\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1157 - accuracy: 0.1172 - val_loss: 3.1915 - val_accuracy: 0.0851\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.1063 - accuracy: 0.1164 - val_loss: 3.1833 - val_accuracy: 0.0993\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0990 - accuracy: 0.1155 - val_loss: 3.1796 - val_accuracy: 0.1017\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0952 - accuracy: 0.1177 - val_loss: 3.1764 - val_accuracy: 0.0993\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0925 - accuracy: 0.1159 - val_loss: 3.1695 - val_accuracy: 0.0969\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0869 - accuracy: 0.1159 - val_loss: 3.1606 - val_accuracy: 0.1087\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0805 - accuracy: 0.1211 - val_loss: 3.1571 - val_accuracy: 0.1064\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0796 - accuracy: 0.1211 - val_loss: 3.1554 - val_accuracy: 0.1064\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0799 - accuracy: 0.1159 - val_loss: 3.1510 - val_accuracy: 0.1017\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0754 - accuracy: 0.1168 - val_loss: 3.1440 - val_accuracy: 0.1017\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0673 - accuracy: 0.1172 - val_loss: 3.1426 - val_accuracy: 0.1017\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0659 - accuracy: 0.1177 - val_loss: 3.1425 - val_accuracy: 0.1017\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0663 - accuracy: 0.1203 - val_loss: 3.1418 - val_accuracy: 0.1064\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0654 - accuracy: 0.1177 - val_loss: 3.1414 - val_accuracy: 0.0993\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0639 - accuracy: 0.1146 - val_loss: 3.1404 - val_accuracy: 0.1017\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0631 - accuracy: 0.1142 - val_loss: 3.1379 - val_accuracy: 0.1017\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0620 - accuracy: 0.1242 - val_loss: 3.1328 - val_accuracy: 0.1017\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0571 - accuracy: 0.1233 - val_loss: 3.1303 - val_accuracy: 0.0993\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0542 - accuracy: 0.1233 - val_loss: 3.1292 - val_accuracy: 0.1087\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0530 - accuracy: 0.1211 - val_loss: 3.1296 - val_accuracy: 0.1040\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0543 - accuracy: 0.1207 - val_loss: 3.1280 - val_accuracy: 0.1064\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0528 - accuracy: 0.1207 - val_loss: 3.1272 - val_accuracy: 0.1040\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0516 - accuracy: 0.1198 - val_loss: 3.1281 - val_accuracy: 0.1064\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 3.0504 - accuracy: 0.1194 - val_loss: 3.1290 - val_accuracy: 0.0993\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0499 - accuracy: 0.1203 - val_loss: 3.1278 - val_accuracy: 0.1064\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0477 - accuracy: 0.1203 - val_loss: 3.1251 - val_accuracy: 0.1064\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0457 - accuracy: 0.1194 - val_loss: 3.1252 - val_accuracy: 0.0993\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0447 - accuracy: 0.1190 - val_loss: 3.1249 - val_accuracy: 0.0993\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0448 - accuracy: 0.1185 - val_loss: 3.1246 - val_accuracy: 0.1017\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0452 - accuracy: 0.1190 - val_loss: 3.1248 - val_accuracy: 0.1064\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 3.0453 - accuracy: 0.1220 - val_loss: 3.1239 - val_accuracy: 0.1040\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0435 - accuracy: 0.1211 - val_loss: 3.1212 - val_accuracy: 0.1064\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0422 - accuracy: 0.1194 - val_loss: 3.1192 - val_accuracy: 0.1135\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0423 - accuracy: 0.1190 - val_loss: 3.1218 - val_accuracy: 0.1064\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0429 - accuracy: 0.1172 - val_loss: 3.1241 - val_accuracy: 0.0993\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0410 - accuracy: 0.1168 - val_loss: 3.1238 - val_accuracy: 0.0922\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0392 - accuracy: 0.1172 - val_loss: 3.1233 - val_accuracy: 0.0993\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0399 - accuracy: 0.1194 - val_loss: 3.1221 - val_accuracy: 0.0969\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0402 - accuracy: 0.1203 - val_loss: 3.1216 - val_accuracy: 0.1017\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0396 - accuracy: 0.1198 - val_loss: 3.1215 - val_accuracy: 0.1040\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0402 - accuracy: 0.1159 - val_loss: 3.1186 - val_accuracy: 0.1087\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0389 - accuracy: 0.1177 - val_loss: 3.1175 - val_accuracy: 0.1040\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0372 - accuracy: 0.1177 - val_loss: 3.1190 - val_accuracy: 0.1040\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0360 - accuracy: 0.1177 - val_loss: 3.1199 - val_accuracy: 0.1040\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0358 - accuracy: 0.1177 - val_loss: 3.1224 - val_accuracy: 0.1017\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0369 - accuracy: 0.1181 - val_loss: 3.1209 - val_accuracy: 0.0993\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0344 - accuracy: 0.1172 - val_loss: 3.1213 - val_accuracy: 0.0993\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0333 - accuracy: 0.1203 - val_loss: 3.1202 - val_accuracy: 0.0922\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0339 - accuracy: 0.1198 - val_loss: 3.1162 - val_accuracy: 0.1064\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0330 - accuracy: 0.1242 - val_loss: 3.1162 - val_accuracy: 0.1040\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0336 - accuracy: 0.1203 - val_loss: 3.1158 - val_accuracy: 0.1017\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0325 - accuracy: 0.1159 - val_loss: 3.1160 - val_accuracy: 0.1017\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0323 - accuracy: 0.1220 - val_loss: 3.1202 - val_accuracy: 0.0946\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0321 - accuracy: 0.1168 - val_loss: 3.1223 - val_accuracy: 0.0922\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.0318 - accuracy: 0.1181 - val_loss: 3.1212 - val_accuracy: 0.1040\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0311 - accuracy: 0.1164 - val_loss: 3.1192 - val_accuracy: 0.1064\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0311 - accuracy: 0.1172 - val_loss: 3.1162 - val_accuracy: 0.1017\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0293 - accuracy: 0.1211 - val_loss: 3.1173 - val_accuracy: 0.1040\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 3.0313 - accuracy: 0.1211 - val_loss: 3.1187 - val_accuracy: 0.1064\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0324 - accuracy: 0.1168 - val_loss: 3.1186 - val_accuracy: 0.1040\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0318 - accuracy: 0.1168 - val_loss: 3.1152 - val_accuracy: 0.1111\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0302 - accuracy: 0.1198 - val_loss: 3.1129 - val_accuracy: 0.1040\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0280 - accuracy: 0.1211 - val_loss: 3.1127 - val_accuracy: 0.1040\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0284 - accuracy: 0.1190 - val_loss: 3.1119 - val_accuracy: 0.0993\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0295 - accuracy: 0.1185 - val_loss: 3.1148 - val_accuracy: 0.0969\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0293 - accuracy: 0.1194 - val_loss: 3.1145 - val_accuracy: 0.0946\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0283 - accuracy: 0.1190 - val_loss: 3.1144 - val_accuracy: 0.1017\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0284 - accuracy: 0.1203 - val_loss: 3.1169 - val_accuracy: 0.0946\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0291 - accuracy: 0.1172 - val_loss: 3.1145 - val_accuracy: 0.1017\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.0283 - accuracy: 0.1177 - val_loss: 3.1119 - val_accuracy: 0.1040\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0264 - accuracy: 0.1181 - val_loss: 3.1154 - val_accuracy: 0.1017\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0266 - accuracy: 0.1185 - val_loss: 3.1151 - val_accuracy: 0.1064\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.0276 - accuracy: 0.1177 - val_loss: 3.1147 - val_accuracy: 0.1064\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0271 - accuracy: 0.1207 - val_loss: 3.1110 - val_accuracy: 0.0898\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0248 - accuracy: 0.1216 - val_loss: 3.1067 - val_accuracy: 0.1017\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0224 - accuracy: 0.1242 - val_loss: 3.1073 - val_accuracy: 0.1040\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0232 - accuracy: 0.1190 - val_loss: 3.1152 - val_accuracy: 0.1017\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0265 - accuracy: 0.1164 - val_loss: 3.1131 - val_accuracy: 0.0993\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0247 - accuracy: 0.1172 - val_loss: 3.1108 - val_accuracy: 0.0946\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0230 - accuracy: 0.1203 - val_loss: 3.1123 - val_accuracy: 0.0993\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0216 - accuracy: 0.1181 - val_loss: 3.1128 - val_accuracy: 0.1040\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0241 - accuracy: 0.1172 - val_loss: 3.1106 - val_accuracy: 0.1040\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0231 - accuracy: 0.1207 - val_loss: 3.1069 - val_accuracy: 0.1017\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0229 - accuracy: 0.1216 - val_loss: 3.1082 - val_accuracy: 0.0993\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 3.0218 - accuracy: 0.1185 - val_loss: 3.1137 - val_accuracy: 0.0969\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 844ms/step - loss: 5.0251 - accuracy: 0.0269 - val_loss: 4.5889 - val_accuracy: 0.0639\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 4.5266 - accuracy: 0.0560 - val_loss: 4.2440 - val_accuracy: 0.0639\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 4.1701 - accuracy: 0.0711 - val_loss: 3.9844 - val_accuracy: 0.0762\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9013 - accuracy: 0.0763 - val_loss: 3.7929 - val_accuracy: 0.0762\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.7021 - accuracy: 0.0794 - val_loss: 3.6421 - val_accuracy: 0.1007\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.5436 - accuracy: 0.1055 - val_loss: 3.5471 - val_accuracy: 0.0860\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.4406 - accuracy: 0.1139 - val_loss: 3.4839 - val_accuracy: 0.0835\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3700 - accuracy: 0.1165 - val_loss: 3.4419 - val_accuracy: 0.0835\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3235 - accuracy: 0.1209 - val_loss: 3.4112 - val_accuracy: 0.0786\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.2905 - accuracy: 0.1156 - val_loss: 3.3845 - val_accuracy: 0.0786\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.2638 - accuracy: 0.1165 - val_loss: 3.3637 - val_accuracy: 0.0811\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.2418 - accuracy: 0.1064 - val_loss: 3.3498 - val_accuracy: 0.1032\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2254 - accuracy: 0.0989 - val_loss: 3.3359 - val_accuracy: 0.1081\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 3.2063 - accuracy: 0.0989 - val_loss: 3.3282 - val_accuracy: 0.0762\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1907 - accuracy: 0.1068 - val_loss: 3.3287 - val_accuracy: 0.0737\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.1807 - accuracy: 0.1117 - val_loss: 3.3302 - val_accuracy: 0.0786\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1723 - accuracy: 0.1143 - val_loss: 3.3271 - val_accuracy: 0.0762\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1614 - accuracy: 0.1165 - val_loss: 3.3257 - val_accuracy: 0.0786\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 3.1543 - accuracy: 0.1183 - val_loss: 3.3230 - val_accuracy: 0.0811\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1472 - accuracy: 0.1200 - val_loss: 3.3141 - val_accuracy: 0.0860\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 3.1339 - accuracy: 0.1174 - val_loss: 3.3014 - val_accuracy: 0.0786\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1182 - accuracy: 0.1187 - val_loss: 3.2914 - val_accuracy: 0.0811\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1079 - accuracy: 0.1174 - val_loss: 3.2840 - val_accuracy: 0.0762\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1026 - accuracy: 0.1183 - val_loss: 3.2758 - val_accuracy: 0.0786\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0963 - accuracy: 0.1192 - val_loss: 3.2655 - val_accuracy: 0.0786\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0890 - accuracy: 0.1205 - val_loss: 3.2573 - val_accuracy: 0.0835\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0834 - accuracy: 0.1178 - val_loss: 3.2498 - val_accuracy: 0.0737\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0786 - accuracy: 0.1209 - val_loss: 3.2430 - val_accuracy: 0.0737\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 3.0750 - accuracy: 0.1196 - val_loss: 3.2353 - val_accuracy: 0.0835\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0704 - accuracy: 0.1196 - val_loss: 3.2295 - val_accuracy: 0.0835\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0672 - accuracy: 0.1222 - val_loss: 3.2235 - val_accuracy: 0.0786\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0639 - accuracy: 0.1214 - val_loss: 3.2178 - val_accuracy: 0.0835\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0609 - accuracy: 0.1196 - val_loss: 3.2151 - val_accuracy: 0.0860\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0606 - accuracy: 0.1187 - val_loss: 3.2101 - val_accuracy: 0.0811\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0579 - accuracy: 0.1183 - val_loss: 3.2019 - val_accuracy: 0.0786\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0521 - accuracy: 0.1178 - val_loss: 3.1963 - val_accuracy: 0.0811\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0496 - accuracy: 0.1187 - val_loss: 3.1952 - val_accuracy: 0.0811\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 3.0493 - accuracy: 0.1178 - val_loss: 3.1936 - val_accuracy: 0.0811\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0475 - accuracy: 0.1174 - val_loss: 3.1908 - val_accuracy: 0.0762\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 3.0455 - accuracy: 0.1187 - val_loss: 3.1875 - val_accuracy: 0.0762\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0427 - accuracy: 0.1227 - val_loss: 3.1884 - val_accuracy: 0.0811\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0423 - accuracy: 0.1218 - val_loss: 3.1913 - val_accuracy: 0.0835\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0420 - accuracy: 0.1236 - val_loss: 3.1933 - val_accuracy: 0.0835\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0411 - accuracy: 0.1240 - val_loss: 3.1931 - val_accuracy: 0.0811\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0403 - accuracy: 0.1222 - val_loss: 3.1889 - val_accuracy: 0.0811\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0371 - accuracy: 0.1231 - val_loss: 3.1872 - val_accuracy: 0.0811\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 3.0357 - accuracy: 0.1222 - val_loss: 3.1879 - val_accuracy: 0.0835\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 3.0354 - accuracy: 0.1227 - val_loss: 3.1894 - val_accuracy: 0.0811\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0348 - accuracy: 0.1205 - val_loss: 3.1930 - val_accuracy: 0.0811\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 3.0354 - accuracy: 0.1178 - val_loss: 3.1927 - val_accuracy: 0.0811\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0329 - accuracy: 0.1165 - val_loss: 3.1901 - val_accuracy: 0.0786\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0297 - accuracy: 0.1174 - val_loss: 3.1910 - val_accuracy: 0.0762\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0305 - accuracy: 0.1192 - val_loss: 3.1903 - val_accuracy: 0.0811\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0299 - accuracy: 0.1183 - val_loss: 3.1913 - val_accuracy: 0.0835\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0295 - accuracy: 0.1209 - val_loss: 3.1934 - val_accuracy: 0.0786\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0285 - accuracy: 0.1214 - val_loss: 3.1932 - val_accuracy: 0.0811\n",
      "OOS Log Loss: 3.0197724843457023\n"
     ]
    }
   ],
   "source": [
    "n_hidden_layers = study.best_params['n_hidden_layers']\n",
    "\n",
    "hidden_layer_neurons = []\n",
    "l1s = []\n",
    "l2s = []\n",
    "for i in range(n_hidden_layers):\n",
    "    hidden_layer_neurons.append(study.best_params[f\"hidden_layer_{i+1}_neurons\"])\n",
    "    l1s.append(study.best_params[f\"hidden_layer_{i+1}_l1\"])\n",
    "    l2s.append(study.best_params[f\"hidden_layer_{i+1}_l2\"])\n",
    "\n",
    "learning_rate = study.best_params[f\"learning_rate\"]\n",
    "batch_size = study.best_params[f\"batch_size\"]\n",
    "\n",
    "y_oos_list = []\n",
    "y_pred_list = []\n",
    "testing_data = []\n",
    "for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "    # make sure to build mod in loop to prevent history\n",
    "    mod = build_and_compile_model(X_train.shape[1:], y_train.shape[1], hidden_layer_neurons, l1s, l2s, learning_rate)\n",
    "\n",
    "    mod.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=500,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    y_preds = mod.predict(X_oos, verbose=0)\n",
    "\n",
    "    df_preds = pd.DataFrame(\n",
    "        y_preds,\n",
    "        columns=y.columns\n",
    "    )\n",
    "\n",
    "    testing_data.append(pd.concat((df_mod_oos.reset_index(drop=True), df_preds), axis=1))\n",
    "\n",
    "\n",
    "    y_oos_list.append(y_oos)\n",
    "    y_pred_list.append(y_preds)\n",
    "\n",
    "df_test = pd.concat(testing_data, ignore_index=True)\n",
    "\n",
    "y_oos_concat = np.vstack(y_oos_list)\n",
    "y_pred_concat = np.vstack(y_pred_list)\n",
    "\n",
    "print(f\"OOS Log Loss: {log_loss(y_oos_concat, y_pred_concat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_distribution(row):\n",
    "    distribution = row[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].astype('float64')/row[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].astype('float64').sum()\n",
    "\n",
    "    return np.random.choice([i for i in range(-4, 56)], p=distribution, size=1_000)\n",
    "\n",
    "# get_random_distribution(df_test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004733432984554061"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_test['Fantasy Points'] < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(22)\n",
    "\n",
    "row = df_test.iloc[1_000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "random_distribution = get_random_distribution(row)\n",
    "\n",
    "ax = sns.kdeplot(random_distribution, fill=True, bw_adjust=1.0, color='blue', label='Projected Fantasy Points Distribution')\n",
    "\n",
    "current_limits = ax.get_ylim()\n",
    "\n",
    "plt.vlines(x=row['Fantasy Points'], ymin=0.0, ymax=1.0, colors=['red'], label='Actual Fantasy Points Scored')\n",
    "\n",
    "ax.set_ylim(current_limits)\n",
    "\n",
    "plt.title(f\"{row['Name'].title()} {row['Season']} Week {row['Week']} Projected Fantasy Points Distribution\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.362440526248877"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "root_mean_squared_error(\n",
    "    df_test['Fantasy Points'],\n",
    "    np.dot(np.array([i for i in range(-4, 56)]), df_test[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].transpose()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.824457712882731"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(\n",
    "    df_test['Fantasy Points'],\n",
    "    np.dot(np.array([i for i in range(-4, 56)]), df_test[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].transpose()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often do players end up in certain percentiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4014"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = [(df_test.iloc[i]['Fantasy Points'] > get_random_distribution(df_test.iloc[i])).mean() for i in range(df_test.shape[0])]\n",
    "\n",
    "len(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(\n",
    "    x=percentiles,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4014.000000\n",
       "mean        0.497587\n",
       "std         0.288988\n",
       "min         0.000000\n",
       "1%          0.000000\n",
       "5%          0.044650\n",
       "10%         0.102300\n",
       "25%         0.252000\n",
       "50%         0.491500\n",
       "75%         0.745000\n",
       "90%         0.904000\n",
       "95%         0.948000\n",
       "99%         0.989000\n",
       "max         1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(percentiles).describe(percentiles=[0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
