{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Week</th>\n",
       "      <th>Name</th>\n",
       "      <th>Position</th>\n",
       "      <th>Team</th>\n",
       "      <th>Fantasy Points</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Position Rank</th>\n",
       "      <th>Adjusted Passing Yards Projection</th>\n",
       "      <th>Adjusted Passing Touchdowns Projection</th>\n",
       "      <th>Adjusted Interceptions Projection</th>\n",
       "      <th>Adjusted Rushing Yards Projection</th>\n",
       "      <th>Adjusted Receiving Yards Projection</th>\n",
       "      <th>Adjusted Receptions Projection</th>\n",
       "      <th>Anytime Touchdown Probability</th>\n",
       "      <th>Location</th>\n",
       "      <th>Team Projected Score</th>\n",
       "      <th>Opponent Projected Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Buffalo Bills</td>\n",
       "      <td>DST</td>\n",
       "      <td>BUF</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.75</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Pittsburgh Steelers</td>\n",
       "      <td>DST</td>\n",
       "      <td>PIT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Baltimore Ravens</td>\n",
       "      <td>DST</td>\n",
       "      <td>BAL</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>New England Patriots</td>\n",
       "      <td>DST</td>\n",
       "      <td>NE</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>Philadelphia Eagles</td>\n",
       "      <td>DST</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>Cincinnati Bengals</td>\n",
       "      <td>DST</td>\n",
       "      <td>CIN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>Detroit Lions</td>\n",
       "      <td>DST</td>\n",
       "      <td>DET</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>New York Giants</td>\n",
       "      <td>DST</td>\n",
       "      <td>NYG</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>Arizona Cardinals</td>\n",
       "      <td>DST</td>\n",
       "      <td>ARI</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>Washington Commanders</td>\n",
       "      <td>DST</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>31.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Season  Week                   Name Position Team  Fantasy Points  Rank  \\\n",
       "0       2020     1          Buffalo Bills      DST  BUF             8.0   NaN   \n",
       "1       2020     1    Pittsburgh Steelers      DST  PIT             8.0   NaN   \n",
       "2       2020     1       Baltimore Ravens      DST  BAL            15.0   NaN   \n",
       "3       2020     1   New England Patriots      DST   NE            11.0   NaN   \n",
       "4       2020     1    Philadelphia Eagles      DST  PHI             3.0   NaN   \n",
       "...      ...   ...                    ...      ...  ...             ...   ...   \n",
       "2011    2023    17     Cincinnati Bengals      DST  CIN             4.0   NaN   \n",
       "2012    2023    17          Detroit Lions      DST  DET             6.0   NaN   \n",
       "2013    2023    17        New York Giants      DST  NYG            16.0   NaN   \n",
       "2014    2023    17      Arizona Cardinals      DST  ARI             2.0   NaN   \n",
       "2015    2023    17  Washington Commanders      DST  WAS             1.0   NaN   \n",
       "\n",
       "      Position Rank  Adjusted Passing Yards Projection  \\\n",
       "0                 1                                NaN   \n",
       "1                 2                                NaN   \n",
       "2                 3                                NaN   \n",
       "3                 4                                NaN   \n",
       "4                 5                                NaN   \n",
       "...             ...                                ...   \n",
       "2011             28                                NaN   \n",
       "2012             29                                NaN   \n",
       "2013             30                                NaN   \n",
       "2014             31                                NaN   \n",
       "2015             32                                NaN   \n",
       "\n",
       "      Adjusted Passing Touchdowns Projection  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "2011                                     NaN   \n",
       "2012                                     NaN   \n",
       "2013                                     NaN   \n",
       "2014                                     NaN   \n",
       "2015                                     NaN   \n",
       "\n",
       "      Adjusted Interceptions Projection  Adjusted Rushing Yards Projection  \\\n",
       "0                                   NaN                                NaN   \n",
       "1                                   NaN                                NaN   \n",
       "2                                   NaN                                NaN   \n",
       "3                                   NaN                                NaN   \n",
       "4                                   NaN                                NaN   \n",
       "...                                 ...                                ...   \n",
       "2011                                NaN                                NaN   \n",
       "2012                                NaN                                NaN   \n",
       "2013                                NaN                                NaN   \n",
       "2014                                NaN                                NaN   \n",
       "2015                                NaN                                NaN   \n",
       "\n",
       "      Adjusted Receiving Yards Projection  Adjusted Receptions Projection  \\\n",
       "0                                     NaN                             NaN   \n",
       "1                                     NaN                             NaN   \n",
       "2                                     NaN                             NaN   \n",
       "3                                     NaN                             NaN   \n",
       "4                                     NaN                             NaN   \n",
       "...                                   ...                             ...   \n",
       "2011                                  NaN                             NaN   \n",
       "2012                                  NaN                             NaN   \n",
       "2013                                  NaN                             NaN   \n",
       "2014                                  NaN                             NaN   \n",
       "2015                                  NaN                             NaN   \n",
       "\n",
       "      Anytime Touchdown Probability  Location  Team Projected Score  \\\n",
       "0                               NaN       1.0                 23.75   \n",
       "1                               NaN      -1.0                 25.00   \n",
       "2                               NaN       1.0                 27.25   \n",
       "3                               NaN       1.0                 24.50   \n",
       "4                               NaN      -1.0                 22.00   \n",
       "...                             ...       ...                   ...   \n",
       "2011                            NaN      -1.0                 19.50   \n",
       "2012                            NaN      -1.0                 24.50   \n",
       "2013                            NaN       1.0                 18.75   \n",
       "2014                            NaN      -1.0                 17.75   \n",
       "2015                            NaN       1.0                 17.25   \n",
       "\n",
       "      Opponent Projected Score  \n",
       "0                        17.25  \n",
       "1                        19.00  \n",
       "2                        20.25  \n",
       "3                        17.00  \n",
       "4                        16.50  \n",
       "...                        ...  \n",
       "2011                     26.50  \n",
       "2012                     29.00  \n",
       "2013                     24.75  \n",
       "2014                     30.25  \n",
       "2015                     31.25  \n",
       "\n",
       "[2016 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "df_mod = pd.read_parquet('../../../data/model_data/model_data_single_output.parquet')\n",
    "\n",
    "df_mod = df_mod.loc[df_mod['Position'] == 'DST', :].reset_index(drop=True)\n",
    "\n",
    "df_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position Rank</th>\n",
       "      <th>Location</th>\n",
       "      <th>Team Projected Score</th>\n",
       "      <th>Opponent Projected Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.75</td>\n",
       "      <td>17.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>19.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.25</td>\n",
       "      <td>20.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>16.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>28</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>19.50</td>\n",
       "      <td>26.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>29</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>29.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.75</td>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>30.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.25</td>\n",
       "      <td>31.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Position Rank  Location  Team Projected Score  Opponent Projected Score\n",
       "0                 1       1.0                 23.75                     17.25\n",
       "1                 2      -1.0                 25.00                     19.00\n",
       "2                 3       1.0                 27.25                     20.25\n",
       "3                 4       1.0                 24.50                     17.00\n",
       "4                 5      -1.0                 22.00                     16.50\n",
       "...             ...       ...                   ...                       ...\n",
       "2011             28      -1.0                 19.50                     26.50\n",
       "2012             29      -1.0                 24.50                     29.00\n",
       "2013             30       1.0                 18.75                     24.75\n",
       "2014             31      -1.0                 17.75                     30.25\n",
       "2015             32       1.0                 17.25                     31.25\n",
       "\n",
       "[2016 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_mod[[\n",
    "    'Position Rank',\n",
    "    'Location',\n",
    "    'Team Projected Score',\n",
    "    'Opponent Projected Score',\n",
    "]].copy()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        8\n",
       "1        8\n",
       "2       15\n",
       "3       11\n",
       "4        3\n",
       "        ..\n",
       "2011     4\n",
       "2012     6\n",
       "2013    16\n",
       "2014     2\n",
       "2015     1\n",
       "Name: Fantasy Points, Length: 2016, dtype: int32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points_rounded = df_mod['Fantasy Points'].round().astype(int)\n",
    "\n",
    "points_rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-4 Fantasy Points</th>\n",
       "      <th>-3 Fantasy Points</th>\n",
       "      <th>-2 Fantasy Points</th>\n",
       "      <th>-1 Fantasy Points</th>\n",
       "      <th>0 Fantasy Points</th>\n",
       "      <th>1 Fantasy Points</th>\n",
       "      <th>2 Fantasy Points</th>\n",
       "      <th>3 Fantasy Points</th>\n",
       "      <th>4 Fantasy Points</th>\n",
       "      <th>5 Fantasy Points</th>\n",
       "      <th>6 Fantasy Points</th>\n",
       "      <th>7 Fantasy Points</th>\n",
       "      <th>8 Fantasy Points</th>\n",
       "      <th>9 Fantasy Points</th>\n",
       "      <th>10 Fantasy Points</th>\n",
       "      <th>11 Fantasy Points</th>\n",
       "      <th>12 Fantasy Points</th>\n",
       "      <th>13 Fantasy Points</th>\n",
       "      <th>14 Fantasy Points</th>\n",
       "      <th>15 Fantasy Points</th>\n",
       "      <th>16 Fantasy Points</th>\n",
       "      <th>17 Fantasy Points</th>\n",
       "      <th>18 Fantasy Points</th>\n",
       "      <th>19 Fantasy Points</th>\n",
       "      <th>20 Fantasy Points</th>\n",
       "      <th>21 Fantasy Points</th>\n",
       "      <th>22 Fantasy Points</th>\n",
       "      <th>23 Fantasy Points</th>\n",
       "      <th>24 Fantasy Points</th>\n",
       "      <th>25 Fantasy Points</th>\n",
       "      <th>26 Fantasy Points</th>\n",
       "      <th>27 Fantasy Points</th>\n",
       "      <th>28 Fantasy Points</th>\n",
       "      <th>29 Fantasy Points</th>\n",
       "      <th>30 Fantasy Points</th>\n",
       "      <th>31 Fantasy Points</th>\n",
       "      <th>32 Fantasy Points</th>\n",
       "      <th>33 Fantasy Points</th>\n",
       "      <th>34 Fantasy Points</th>\n",
       "      <th>35 Fantasy Points</th>\n",
       "      <th>36 Fantasy Points</th>\n",
       "      <th>37 Fantasy Points</th>\n",
       "      <th>38 Fantasy Points</th>\n",
       "      <th>39 Fantasy Points</th>\n",
       "      <th>40 Fantasy Points</th>\n",
       "      <th>41 Fantasy Points</th>\n",
       "      <th>42 Fantasy Points</th>\n",
       "      <th>43 Fantasy Points</th>\n",
       "      <th>44 Fantasy Points</th>\n",
       "      <th>45 Fantasy Points</th>\n",
       "      <th>46 Fantasy Points</th>\n",
       "      <th>47 Fantasy Points</th>\n",
       "      <th>48 Fantasy Points</th>\n",
       "      <th>49 Fantasy Points</th>\n",
       "      <th>50 Fantasy Points</th>\n",
       "      <th>51 Fantasy Points</th>\n",
       "      <th>52 Fantasy Points</th>\n",
       "      <th>53 Fantasy Points</th>\n",
       "      <th>54 Fantasy Points</th>\n",
       "      <th>55 Fantasy Points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2016 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      -4 Fantasy Points  -3 Fantasy Points  -2 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      -1 Fantasy Points  0 Fantasy Points  1 Fantasy Points  2 Fantasy Points  \\\n",
       "0                   0.0               0.0               0.0               0.0   \n",
       "1                   0.0               0.0               0.0               0.0   \n",
       "2                   0.0               0.0               0.0               0.0   \n",
       "3                   0.0               0.0               0.0               0.0   \n",
       "4                   0.0               0.0               0.0               0.0   \n",
       "...                 ...               ...               ...               ...   \n",
       "2011                0.0               0.0               0.0               0.0   \n",
       "2012                0.0               0.0               0.0               0.0   \n",
       "2013                0.0               0.0               0.0               0.0   \n",
       "2014                0.0               0.0               0.0               1.0   \n",
       "2015                0.0               0.0               1.0               0.0   \n",
       "\n",
       "      3 Fantasy Points  4 Fantasy Points  5 Fantasy Points  6 Fantasy Points  \\\n",
       "0                  0.0               0.0               0.0               0.0   \n",
       "1                  0.0               0.0               0.0               0.0   \n",
       "2                  0.0               0.0               0.0               0.0   \n",
       "3                  0.0               0.0               0.0               0.0   \n",
       "4                  1.0               0.0               0.0               0.0   \n",
       "...                ...               ...               ...               ...   \n",
       "2011               0.0               1.0               0.0               0.0   \n",
       "2012               0.0               0.0               0.0               1.0   \n",
       "2013               0.0               0.0               0.0               0.0   \n",
       "2014               0.0               0.0               0.0               0.0   \n",
       "2015               0.0               0.0               0.0               0.0   \n",
       "\n",
       "      7 Fantasy Points  8 Fantasy Points  9 Fantasy Points  10 Fantasy Points  \\\n",
       "0                  0.0               1.0               0.0                0.0   \n",
       "1                  0.0               1.0               0.0                0.0   \n",
       "2                  0.0               0.0               0.0                0.0   \n",
       "3                  0.0               0.0               0.0                0.0   \n",
       "4                  0.0               0.0               0.0                0.0   \n",
       "...                ...               ...               ...                ...   \n",
       "2011               0.0               0.0               0.0                0.0   \n",
       "2012               0.0               0.0               0.0                0.0   \n",
       "2013               0.0               0.0               0.0                0.0   \n",
       "2014               0.0               0.0               0.0                0.0   \n",
       "2015               0.0               0.0               0.0                0.0   \n",
       "\n",
       "      11 Fantasy Points  12 Fantasy Points  13 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   1.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      14 Fantasy Points  15 Fantasy Points  16 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                1.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                1.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      17 Fantasy Points  18 Fantasy Points  19 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      20 Fantasy Points  21 Fantasy Points  22 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      23 Fantasy Points  24 Fantasy Points  25 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      26 Fantasy Points  27 Fantasy Points  28 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      29 Fantasy Points  30 Fantasy Points  31 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      32 Fantasy Points  33 Fantasy Points  34 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      35 Fantasy Points  36 Fantasy Points  37 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      38 Fantasy Points  39 Fantasy Points  40 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      41 Fantasy Points  42 Fantasy Points  43 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      44 Fantasy Points  45 Fantasy Points  46 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      47 Fantasy Points  48 Fantasy Points  49 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      50 Fantasy Points  51 Fantasy Points  52 Fantasy Points  \\\n",
       "0                   0.0                0.0                0.0   \n",
       "1                   0.0                0.0                0.0   \n",
       "2                   0.0                0.0                0.0   \n",
       "3                   0.0                0.0                0.0   \n",
       "4                   0.0                0.0                0.0   \n",
       "...                 ...                ...                ...   \n",
       "2011                0.0                0.0                0.0   \n",
       "2012                0.0                0.0                0.0   \n",
       "2013                0.0                0.0                0.0   \n",
       "2014                0.0                0.0                0.0   \n",
       "2015                0.0                0.0                0.0   \n",
       "\n",
       "      53 Fantasy Points  54 Fantasy Points  55 Fantasy Points  \n",
       "0                   0.0                0.0                0.0  \n",
       "1                   0.0                0.0                0.0  \n",
       "2                   0.0                0.0                0.0  \n",
       "3                   0.0                0.0                0.0  \n",
       "4                   0.0                0.0                0.0  \n",
       "...                 ...                ...                ...  \n",
       "2011                0.0                0.0                0.0  \n",
       "2012                0.0                0.0                0.0  \n",
       "2013                0.0                0.0                0.0  \n",
       "2014                0.0                0.0                0.0  \n",
       "2015                0.0                0.0                0.0  \n",
       "\n",
       "[2016 rows x 60 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# first column: -5 points scored\n",
    "# last column: 55 points scored\n",
    "y = np.zeros(shape=(points_rounded.shape[0], 60))\n",
    "\n",
    "for i in range(y.shape[0]):\n",
    "    y[i, points_rounded.iloc[i] + 4] = 1\n",
    "\n",
    "y = pd.DataFrame(\n",
    "    y,\n",
    "    columns=[f\"{i - 4} Fantasy Points\" for i in range(y.shape[1])]\n",
    ")\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2020 Week 1\n",
       "1        2020 Week 1\n",
       "2        2020 Week 1\n",
       "3        2020 Week 1\n",
       "4        2020 Week 1\n",
       "            ...     \n",
       "2011    2023 Week 17\n",
       "2012    2023 Week 17\n",
       "2013    2023 Week 17\n",
       "2014    2023 Week 17\n",
       "2015    2023 Week 17\n",
       "Length: 2016, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = df_mod['Season'].astype(str) + ' Week ' + df_mod['Week'].astype(str)\n",
    "\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold ID</th>\n",
       "      <th>Season Week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022 Week 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2023 Week 16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2021 Week 11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>2020 Week 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>2023 Week 14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>2021 Week 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>2022 Week 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>2022 Week 12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fold ID   Season Week\n",
       "0         0   2022 Week 3\n",
       "1         0   2021 Week 7\n",
       "2         0   2021 Week 1\n",
       "3         0  2023 Week 16\n",
       "4         0  2021 Week 11\n",
       "..      ...           ...\n",
       "62        2  2020 Week 15\n",
       "63        2  2023 Week 14\n",
       "64        2   2021 Week 5\n",
       "65        2   2022 Week 6\n",
       "66        2  2022 Week 12\n",
       "\n",
       "[67 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_folds = pd.read_parquet('../../../data/model_data/folds.parquet')\n",
    "\n",
    "df_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1106, 4) (216, 4) (694, 4) (1106, 60) (216, 60) (694, 60) (694, 18)\n",
      "(1156, 4) (212, 4) (648, 4) (1156, 60) (212, 60) (648, 60) (648, 18)\n",
      "(1138, 4) (204, 4) (674, 4) (1138, 60) (204, 60) (674, 60) (674, 18)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# splitter = GroupKFold(n_splits=3)\n",
    "\n",
    "cv_data = []\n",
    "# for is_indexes, oos_indexes in splitter.split(X=X, y=y, groups=groups):\n",
    "for fold in df_folds['Fold ID'].unique():\n",
    "    oos_season_week = df_folds.loc[df_folds['Fold ID'] == fold, 'Season Week']\n",
    "    is_indexes = df_mod.loc[~groups.isin(oos_season_week), :].index\n",
    "    oos_indexes = df_mod.loc[groups.isin(oos_season_week), :].index\n",
    "    # split\n",
    "    X_is = X.iloc[is_indexes]\n",
    "    X_oos = X.iloc[oos_indexes]\n",
    "\n",
    "    y_is = y.iloc[is_indexes]\n",
    "    y_oos = y.iloc[oos_indexes]\n",
    "\n",
    "    groups_is = groups.iloc[is_indexes]\n",
    "    df_mod_oos = df_mod.iloc[oos_indexes]\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.15, random_state=22)\n",
    "    for train_indexes, val_indexes in gss.split(X=X_is, y=y_is, groups=groups_is):\n",
    "            X_train = X_is.iloc[train_indexes]\n",
    "            X_val = X_is.iloc[val_indexes]\n",
    "\n",
    "            y_train = y_is.iloc[train_indexes]\n",
    "            y_val = y_is.iloc[val_indexes]\n",
    "\n",
    "    # impute\n",
    "    scaler = StandardScaler()\n",
    "    imputer = IterativeImputer(initial_strategy='median', max_iter=100)\n",
    "\n",
    "    X_train_fill_na = imputer.fit_transform(scaler.fit_transform(X_train))\n",
    "    X_train[X_train.columns] = scaler.inverse_transform(X_train_fill_na).copy()\n",
    "\n",
    "    scaler2 = MinMaxScaler(clip=True)  # maybe normalize and clip instead of standardize?\n",
    "    scaler3 = StandardScaler()\n",
    "    X_train[X_train.columns] = scaler3.fit_transform(scaler2.fit_transform(X_train)).copy()\n",
    "\n",
    "    X_val_fill_na = imputer.transform(scaler.transform(X_val))\n",
    "    X_val[X_val.columns] = scaler.inverse_transform(X_val_fill_na).copy()\n",
    "\n",
    "    X_val[X_val.columns] = scaler3.transform(scaler2.transform(X_val)).copy()\n",
    "\n",
    "    X_oos_fill_na = imputer.transform(scaler.transform(X_oos))\n",
    "    X_oos[X_oos.columns] = scaler.inverse_transform(X_oos_fill_na).copy()\n",
    "\n",
    "    X_oos[X_oos.columns] = scaler3.transform(scaler2.transform(X_oos)).copy()\n",
    "\n",
    "    cv_data.append((X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos))\n",
    "\n",
    "for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "    print(X_train.shape, X_val.shape, X_oos.shape, y_train.shape, y_val.shape, y_oos.shape, df_mod_oos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 4)]               0         \n",
      "                                                                 \n",
      " hidden_1 (Dense)            (None, 128)               640       \n",
      "                                                                 \n",
      " hidden_2 (Dense)            (None, 32)                4128      \n",
      "                                                                 \n",
      " outputs (Dense)             (None, 60)                1980      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,748\n",
      "Trainable params: 6,748\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.config.experimental import enable_op_determinism\n",
    "from tensorflow.random import set_seed\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "\n",
    "def build_and_compile_model(input_shape: tuple, output_shape: int, hidden_layer_neurons: list, l1s: list, l2s: list, learning_rate: float):\n",
    "    enable_op_determinism()\n",
    "    set_seed(22)\n",
    "    \n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "    h = inputs\n",
    "    for i, neurons in enumerate(hidden_layer_neurons):\n",
    "        h = Dense(\n",
    "            neurons, \n",
    "            activation='relu', \n",
    "            kernel_initializer=GlorotNormal(seed=22), \n",
    "            kernel_regularizer=L1L2(l1=l1s[i], l2=l2s[i]), \n",
    "            name=f\"hidden_{i+1}\"\n",
    "        )(h)\n",
    "\n",
    "    outputs = Dense(output_shape, activation='softmax', kernel_initializer=GlorotNormal(seed=22), name='outputs')(h)\n",
    "\n",
    "    mod = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    mod.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return mod\n",
    "\n",
    "mod = build_and_compile_model(X.shape[1:], y.shape[1], [128, 32], [0, 0.01], [0, 0.01], learning_rate=0.001)\n",
    "\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhugh\\anaconda3\\envs\\clean2\\lib\\site-packages\\optuna\\_experimental.py:30: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2024-10-22 14:35:10,931] A new study created in memory with name: no-name-9d924e1e-7616-43b1-a546-ba6e78c45bba\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fc284f273c4c0cb1a1e69e55c9c43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:35:27,320] Trial 0 finished with value: 3.1005228090109362 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.022040451663772567, 'hidden_layer_1_l2': 0.08119509205386867, 'learning_rate': 0.01094741868844976, 'batch_size': 2048}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:35:37,618] Trial 1 finished with value: 3.13424878962863 and parameters: {'n_hidden_layers': 3, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.058428964315689495, 'hidden_layer_1_l2': 0.07026355188654519, 'hidden_layer_2_neurons': 128, 'hidden_layer_2_l1': 0.08749277452777171, 'hidden_layer_2_l2': 0.07449320773686179, 'hidden_layer_3_neurons': 256, 'hidden_layer_3_l1': 0.009588460991804116, 'hidden_layer_3_l2': 0.004521011190769353, 'learning_rate': 0.07163458468004151, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:35:50,975] Trial 2 finished with value: 3.139768320978845 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 64, 'hidden_layer_1_l1': 0.09115369973853776, 'hidden_layer_1_l2': 0.008625567976924198, 'hidden_layer_2_neurons': 2048, 'hidden_layer_2_l1': 0.0005512411903590642, 'hidden_layer_2_l2': 0.03576431697413079, 'learning_rate': 0.09578334240413691, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:36:01,967] Trial 3 finished with value: 3.11264092039704 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 1024, 'hidden_layer_1_l1': 0.08620878124622662, 'hidden_layer_1_l2': 0.06351961895274903, 'learning_rate': 0.07275008619568284, 'batch_size': 4096}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:36:11,058] Trial 4 finished with value: 3.1225426096200066 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 1024, 'hidden_layer_1_l1': 0.02024276263846314, 'hidden_layer_1_l2': 0.08721894394962987, 'learning_rate': 0.06424371980220045, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:36:24,511] Trial 5 finished with value: 3.1005530776168486 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.05653980354893057, 'hidden_layer_1_l2': 0.00345150171194456, 'learning_rate': 0.0885147769978044, 'batch_size': 16384}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:36:38,901] Trial 6 finished with value: 3.132241107531792 and parameters: {'n_hidden_layers': 3, 'hidden_layer_1_neurons': 256, 'hidden_layer_1_l1': 0.07564442330254927, 'hidden_layer_1_l2': 0.045177882434907994, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.08362472880832089, 'hidden_layer_2_l2': 0.05103829122196473, 'hidden_layer_3_neurons': 128, 'hidden_layer_3_l1': 0.06951388599043494, 'hidden_layer_3_l2': 0.0051964104142108065, 'learning_rate': 0.09447015559422758, 'batch_size': 2048}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:36:51,354] Trial 7 finished with value: 3.1302610930889605 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.08592805490779229, 'hidden_layer_1_l2': 0.0407904418229531, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.025309932195697216, 'hidden_layer_2_l2': 0.03508986025005804, 'learning_rate': 0.06905762708317247, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:37:01,139] Trial 8 finished with value: 3.101623194820146 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.004671699281628905, 'hidden_layer_1_l2': 0.056923526796298245, 'learning_rate': 0.09827798409489276, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:37:12,377] Trial 9 finished with value: 3.1447970216479844 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 256, 'hidden_layer_1_l1': 0.0004424057058423636, 'hidden_layer_1_l2': 0.06813144847420316, 'hidden_layer_2_neurons': 64, 'hidden_layer_2_l1': 0.08249019408071431, 'hidden_layer_2_l2': 0.04359087388902699, 'learning_rate': 0.05221946484311475, 'batch_size': 1024}. Best is trial 0 with value: 3.1005228090109362.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:37:26,110] Trial 10 finished with value: 3.0994437941916817 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.020822305720339832, 'hidden_layer_1_l2': 0.09105201059054474, 'learning_rate': 0.03633285507832701, 'batch_size': 2048}. Best is trial 10 with value: 3.0994437941916817.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:37:43,008] Trial 11 finished with value: 3.1034350341851136 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 1024, 'hidden_layer_1_l1': 0.02212847698075585, 'hidden_layer_1_l2': 0.0710101001486778, 'learning_rate': 0.01576495928001541, 'batch_size': 2048}. Best is trial 10 with value: 3.0994437941916817.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:37:58,425] Trial 12 finished with value: 3.097120284820966 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.009972878789203367, 'hidden_layer_1_l2': 0.09795208341638789, 'learning_rate': 0.01762343174680706, 'batch_size': 8192}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:38:12,004] Trial 13 finished with value: 3.102157082894067 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.02379020894960765, 'hidden_layer_1_l2': 0.09660691266249859, 'learning_rate': 0.04845148095888093, 'batch_size': 8192}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:38:25,938] Trial 14 finished with value: 3.1419158780095007 and parameters: {'n_hidden_layers': 3, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.0011362657820468622, 'hidden_layer_1_l2': 0.0807641316297729, 'hidden_layer_2_neurons': 512, 'hidden_layer_2_l1': 0.04490480620139892, 'hidden_layer_2_l2': 0.09940529653696407, 'hidden_layer_3_neurons': 512, 'hidden_layer_3_l1': 0.09590393621471581, 'hidden_layer_3_l2': 0.09350909781333765, 'learning_rate': 0.02333023751468171, 'batch_size': 16384}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:38:37,870] Trial 15 finished with value: 3.105343408697541 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 128, 'hidden_layer_1_l1': 0.0352728673512092, 'hidden_layer_1_l2': 0.06035408080311322, 'learning_rate': 0.06578545315242046, 'batch_size': 2048}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:38:50,171] Trial 16 finished with value: 3.113112702070165 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 2048, 'hidden_layer_1_l1': 0.0017160411761518342, 'hidden_layer_1_l2': 0.09901166479356358, 'learning_rate': 0.05211905265016894, 'batch_size': 2048}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:39:09,319] Trial 17 finished with value: 3.1307237089496924 and parameters: {'n_hidden_layers': 2, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.043062927799839695, 'hidden_layer_1_l2': 0.09536025359098428, 'hidden_layer_2_neurons': 256, 'hidden_layer_2_l1': 0.04935473615279186, 'hidden_layer_2_l2': 0.008411919297923787, 'learning_rate': 0.02176214482871601, 'batch_size': 32768}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:39:22,377] Trial 18 finished with value: 3.1015190385837763 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 32, 'hidden_layer_1_l1': 0.026345715371129053, 'hidden_layer_1_l2': 0.07995828746316233, 'learning_rate': 0.026139815008333737, 'batch_size': 8192}. Best is trial 12 with value: 3.097120284820966.\n",
      "(2016, 60) (2016, 60)\n",
      "[I 2024-10-22 14:39:37,319] Trial 19 finished with value: 3.1014321110211944 and parameters: {'n_hidden_layers': 1, 'hidden_layer_1_neurons': 64, 'hidden_layer_1_l1': 0.04984064488240802, 'hidden_layer_1_l2': 0.08370316060890715, 'learning_rate': 0.0441879449959942, 'batch_size': 16384}. Best is trial 12 with value: 3.097120284820966.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_hidden_layers': 1,\n",
       " 'hidden_layer_1_neurons': 128,\n",
       " 'hidden_layer_1_l1': 0.009972878789203367,\n",
       " 'hidden_layer_1_l2': 0.09795208341638789,\n",
       " 'learning_rate': 0.01762343174680706,\n",
       " 'batch_size': 8192}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "import optuna\n",
    "\n",
    "def objective(trial, cv_data=cv_data):\n",
    "# model tuning\n",
    "    n_hidden_layers = trial.suggest_int(f\"n_hidden_layers\", 1, 3)\n",
    "\n",
    "    hidden_layer_neurons = []\n",
    "    l1s = []\n",
    "    l2s = []\n",
    "    for i in range(n_hidden_layers):\n",
    "        hidden_layer_neurons.append(trial.suggest_categorical(f\"hidden_layer_{i+1}_neurons\", [2**n for n in range(5, 12)]))  # change to (3, 12)\n",
    "        # hidden_layer_neurons.append(trial.suggest_categorical(f\"hidden_layer_{i+1}_neurons\", [2**n for n in range(4, 9)]))  # bump this up\n",
    "        l1s.append(trial.suggest_float(f\"hidden_layer_{i+1}_l1\", 0.0, 0.1))  # change to (0.0, 0.05)\n",
    "        l2s.append(trial.suggest_float(f\"hidden_layer_{i+1}_l2\", 0.0, 0.1))  # change to (0.0, 0.20)\n",
    "\n",
    "    learning_rate = trial.suggest_float(f\"learning_rate\", 0.01, 0.10)\n",
    "    batch_size = trial.suggest_categorical(f\"batch_size\", [2**n for n in range(10, 16)])\n",
    "    # batch_size = trial.suggest_categorical(f\"batch_size\", [2**n for n in range(4, 12)])  # bump this up\n",
    "\n",
    "    # cross validation\n",
    "    y_oos_list = []\n",
    "    y_pred_list = []\n",
    "    for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "        # make sure to build mod in loop to prevent history\n",
    "        mod = build_and_compile_model(X_train.shape[1:], y_train.shape[1], hidden_layer_neurons, l1s, l2s, learning_rate)\n",
    "\n",
    "        mod.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=batch_size,\n",
    "            epochs=500,\n",
    "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        y_oos_list.append(y_oos)\n",
    "        y_pred_list.append(mod.predict(X_oos, verbose=0))\n",
    "\n",
    "\n",
    "    y_oos_concat = np.vstack(y_oos_list)\n",
    "    y_pred_concat = np.vstack(y_pred_list)\n",
    "\n",
    "    print(y_oos_concat.shape, y_pred_concat.shape)\n",
    "\n",
    "    return log_loss(y_oos_concat, y_pred_concat)\n",
    "\n",
    "study = optuna.create_study(direction='minimize', sampler=optuna.samplers.TPESampler(seed=22, n_startup_trials=10, multivariate=True, warn_independent_sampling=False))\n",
    "study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.097120284820966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 5.3913 - accuracy: 0.0045 - val_loss: 4.8637 - val_accuracy: 0.0556\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.8832 - accuracy: 0.0633 - val_loss: 4.4805 - val_accuracy: 0.0602\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.5003 - accuracy: 0.0660 - val_loss: 4.1761 - val_accuracy: 0.0741\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.1941 - accuracy: 0.0750 - val_loss: 3.9311 - val_accuracy: 0.0741\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.9460 - accuracy: 0.0759 - val_loss: 3.7268 - val_accuracy: 0.0787\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.7383 - accuracy: 0.0805 - val_loss: 3.5547 - val_accuracy: 0.0741\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.5650 - accuracy: 0.0787 - val_loss: 3.4194 - val_accuracy: 0.0741\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.4316 - accuracy: 0.0850 - val_loss: 3.3261 - val_accuracy: 0.0880\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.3438 - accuracy: 0.0895 - val_loss: 3.2728 - val_accuracy: 0.0972\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2991 - accuracy: 0.0922 - val_loss: 3.2468 - val_accuracy: 0.0926\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2810 - accuracy: 0.0931 - val_loss: 3.2296 - val_accuracy: 0.1019\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2709 - accuracy: 0.0913 - val_loss: 3.2124 - val_accuracy: 0.1111\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2580 - accuracy: 0.0895 - val_loss: 3.1913 - val_accuracy: 0.1065\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.2376 - accuracy: 0.0904 - val_loss: 3.1714 - val_accuracy: 0.0972\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2148 - accuracy: 0.0913 - val_loss: 3.1589 - val_accuracy: 0.0926\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1969 - accuracy: 0.0931 - val_loss: 3.1546 - val_accuracy: 0.0926\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1849 - accuracy: 0.0913 - val_loss: 3.1544 - val_accuracy: 0.0926\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1766 - accuracy: 0.0913 - val_loss: 3.1547 - val_accuracy: 0.0880\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.1697 - accuracy: 0.0940 - val_loss: 3.1526 - val_accuracy: 0.1019\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1620 - accuracy: 0.0976 - val_loss: 3.1464 - val_accuracy: 0.0880\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1533 - accuracy: 0.0922 - val_loss: 3.1367 - val_accuracy: 0.0972\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1433 - accuracy: 0.0913 - val_loss: 3.1272 - val_accuracy: 0.1111\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1349 - accuracy: 0.0949 - val_loss: 3.1183 - val_accuracy: 0.1065\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1278 - accuracy: 0.0922 - val_loss: 3.1101 - val_accuracy: 0.0972\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1212 - accuracy: 0.0877 - val_loss: 3.1020 - val_accuracy: 0.1204\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 3.1145 - accuracy: 0.0913 - val_loss: 3.0945 - val_accuracy: 0.1204\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1081 - accuracy: 0.0967 - val_loss: 3.0877 - val_accuracy: 0.1157\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1019 - accuracy: 0.0886 - val_loss: 3.0823 - val_accuracy: 0.1250\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0967 - accuracy: 0.0922 - val_loss: 3.0770 - val_accuracy: 0.1157\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0917 - accuracy: 0.0949 - val_loss: 3.0721 - val_accuracy: 0.1204\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0873 - accuracy: 0.0931 - val_loss: 3.0680 - val_accuracy: 0.1111\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0833 - accuracy: 0.0895 - val_loss: 3.0645 - val_accuracy: 0.1065\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0797 - accuracy: 0.0913 - val_loss: 3.0625 - val_accuracy: 0.1157\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0771 - accuracy: 0.0913 - val_loss: 3.0615 - val_accuracy: 0.1157\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0749 - accuracy: 0.0895 - val_loss: 3.0613 - val_accuracy: 0.1157\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0729 - accuracy: 0.0922 - val_loss: 3.0614 - val_accuracy: 0.1204\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0706 - accuracy: 0.0958 - val_loss: 3.0616 - val_accuracy: 0.1157\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0681 - accuracy: 0.0913 - val_loss: 3.0621 - val_accuracy: 0.1296\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0665 - accuracy: 0.0931 - val_loss: 3.0620 - val_accuracy: 0.1204\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0649 - accuracy: 0.0895 - val_loss: 3.0606 - val_accuracy: 0.1296\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0632 - accuracy: 0.0922 - val_loss: 3.0585 - val_accuracy: 0.1296\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0610 - accuracy: 0.0949 - val_loss: 3.0560 - val_accuracy: 0.1250\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0584 - accuracy: 0.0922 - val_loss: 3.0540 - val_accuracy: 0.1157\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0560 - accuracy: 0.0868 - val_loss: 3.0534 - val_accuracy: 0.1111\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0545 - accuracy: 0.0904 - val_loss: 3.0534 - val_accuracy: 0.1204\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0536 - accuracy: 0.0976 - val_loss: 3.0528 - val_accuracy: 0.1296\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0528 - accuracy: 0.1004 - val_loss: 3.0515 - val_accuracy: 0.1250\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0523 - accuracy: 0.1004 - val_loss: 3.0493 - val_accuracy: 0.1250\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0513 - accuracy: 0.0958 - val_loss: 3.0478 - val_accuracy: 0.1157\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0504 - accuracy: 0.0958 - val_loss: 3.0470 - val_accuracy: 0.1204\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0493 - accuracy: 0.0949 - val_loss: 3.0466 - val_accuracy: 0.1250\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0480 - accuracy: 0.0958 - val_loss: 3.0471 - val_accuracy: 0.1250\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0477 - accuracy: 0.0931 - val_loss: 3.0468 - val_accuracy: 0.1296\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0472 - accuracy: 0.0940 - val_loss: 3.0448 - val_accuracy: 0.1296\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0461 - accuracy: 0.0922 - val_loss: 3.0425 - val_accuracy: 0.1250\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0451 - accuracy: 0.0958 - val_loss: 3.0414 - val_accuracy: 0.1250\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0442 - accuracy: 0.0949 - val_loss: 3.0412 - val_accuracy: 0.1250\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0430 - accuracy: 0.0940 - val_loss: 3.0425 - val_accuracy: 0.1296\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0428 - accuracy: 0.0940 - val_loss: 3.0433 - val_accuracy: 0.1296\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0424 - accuracy: 0.0958 - val_loss: 3.0432 - val_accuracy: 0.1296\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.0420 - accuracy: 0.0986 - val_loss: 3.0421 - val_accuracy: 0.1250\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0413 - accuracy: 0.0958 - val_loss: 3.0418 - val_accuracy: 0.1250\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0408 - accuracy: 0.0958 - val_loss: 3.0419 - val_accuracy: 0.1204\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0403 - accuracy: 0.0958 - val_loss: 3.0422 - val_accuracy: 0.1250\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0398 - accuracy: 0.0958 - val_loss: 3.0423 - val_accuracy: 0.1250\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0393 - accuracy: 0.0949 - val_loss: 3.0420 - val_accuracy: 0.1250\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0388 - accuracy: 0.0940 - val_loss: 3.0415 - val_accuracy: 0.1250\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 952ms/step - loss: 5.3854 - accuracy: 0.0069 - val_loss: 4.8767 - val_accuracy: 0.0613\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 4.8780 - accuracy: 0.0666 - val_loss: 4.5047 - val_accuracy: 0.0613\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.4955 - accuracy: 0.0718 - val_loss: 4.2081 - val_accuracy: 0.0425\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 4.1897 - accuracy: 0.0813 - val_loss: 3.9685 - val_accuracy: 0.0472\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.9414 - accuracy: 0.0865 - val_loss: 3.7676 - val_accuracy: 0.0472\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.7339 - accuracy: 0.0882 - val_loss: 3.5977 - val_accuracy: 0.0519\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.5598 - accuracy: 0.0874 - val_loss: 3.4655 - val_accuracy: 0.0377\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.4246 - accuracy: 0.0822 - val_loss: 3.3792 - val_accuracy: 0.0472\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.3347 - accuracy: 0.0882 - val_loss: 3.3340 - val_accuracy: 0.0472\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2865 - accuracy: 0.0908 - val_loss: 3.3167 - val_accuracy: 0.0425\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.2643 - accuracy: 0.1012 - val_loss: 3.3083 - val_accuracy: 0.0472\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.2520 - accuracy: 0.1029 - val_loss: 3.2954 - val_accuracy: 0.0472\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.2394 - accuracy: 0.1012 - val_loss: 3.2740 - val_accuracy: 0.0519\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2226 - accuracy: 0.0969 - val_loss: 3.2472 - val_accuracy: 0.0613\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2036 - accuracy: 0.0995 - val_loss: 3.2230 - val_accuracy: 0.0566\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1880 - accuracy: 0.1021 - val_loss: 3.2055 - val_accuracy: 0.0566\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1781 - accuracy: 0.1012 - val_loss: 3.1938 - val_accuracy: 0.0566\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1716 - accuracy: 0.0978 - val_loss: 3.1863 - val_accuracy: 0.0613\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1667 - accuracy: 0.0995 - val_loss: 3.1801 - val_accuracy: 0.0613\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1606 - accuracy: 0.0995 - val_loss: 3.1735 - val_accuracy: 0.0613\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1518 - accuracy: 0.1029 - val_loss: 3.1678 - val_accuracy: 0.0472\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1424 - accuracy: 0.1029 - val_loss: 3.1633 - val_accuracy: 0.0472\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1336 - accuracy: 0.1064 - val_loss: 3.1588 - val_accuracy: 0.0660\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1245 - accuracy: 0.1029 - val_loss: 3.1562 - val_accuracy: 0.0472\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1175 - accuracy: 0.1064 - val_loss: 3.1540 - val_accuracy: 0.0519\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1108 - accuracy: 0.1012 - val_loss: 3.1510 - val_accuracy: 0.0425\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.1035 - accuracy: 0.1047 - val_loss: 3.1489 - val_accuracy: 0.0377\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0974 - accuracy: 0.1012 - val_loss: 3.1468 - val_accuracy: 0.0425\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0922 - accuracy: 0.1021 - val_loss: 3.1438 - val_accuracy: 0.0425\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0870 - accuracy: 0.1012 - val_loss: 3.1406 - val_accuracy: 0.0377\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0828 - accuracy: 0.1003 - val_loss: 3.1370 - val_accuracy: 0.0377\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0793 - accuracy: 0.1029 - val_loss: 3.1333 - val_accuracy: 0.0425\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0767 - accuracy: 0.1012 - val_loss: 3.1297 - val_accuracy: 0.0566\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0742 - accuracy: 0.0986 - val_loss: 3.1259 - val_accuracy: 0.0566\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0716 - accuracy: 0.1021 - val_loss: 3.1224 - val_accuracy: 0.0613\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0687 - accuracy: 0.1047 - val_loss: 3.1196 - val_accuracy: 0.0425\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0659 - accuracy: 0.1064 - val_loss: 3.1176 - val_accuracy: 0.0377\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0640 - accuracy: 0.1125 - val_loss: 3.1161 - val_accuracy: 0.0377\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0628 - accuracy: 0.1047 - val_loss: 3.1148 - val_accuracy: 0.0425\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0617 - accuracy: 0.1029 - val_loss: 3.1124 - val_accuracy: 0.0472\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0596 - accuracy: 0.1021 - val_loss: 3.1100 - val_accuracy: 0.0472\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0577 - accuracy: 0.1021 - val_loss: 3.1077 - val_accuracy: 0.0472\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0560 - accuracy: 0.1012 - val_loss: 3.1058 - val_accuracy: 0.0425\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0546 - accuracy: 0.1003 - val_loss: 3.1043 - val_accuracy: 0.0425\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0529 - accuracy: 0.1021 - val_loss: 3.1041 - val_accuracy: 0.0425\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 3.0515 - accuracy: 0.0986 - val_loss: 3.1042 - val_accuracy: 0.0377\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0503 - accuracy: 0.0995 - val_loss: 3.1052 - val_accuracy: 0.0377\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0497 - accuracy: 0.1012 - val_loss: 3.1061 - val_accuracy: 0.0472\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 3.0488 - accuracy: 0.1021 - val_loss: 3.1068 - val_accuracy: 0.0519\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0480 - accuracy: 0.1029 - val_loss: 3.1071 - val_accuracy: 0.0519\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0471 - accuracy: 0.1047 - val_loss: 3.1068 - val_accuracy: 0.0519\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0460 - accuracy: 0.1064 - val_loss: 3.1058 - val_accuracy: 0.0425\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0450 - accuracy: 0.1047 - val_loss: 3.1050 - val_accuracy: 0.0377\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 3.0449 - accuracy: 0.1029 - val_loss: 3.1034 - val_accuracy: 0.0330\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0445 - accuracy: 0.1021 - val_loss: 3.1013 - val_accuracy: 0.0425\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0434 - accuracy: 0.1003 - val_loss: 3.1002 - val_accuracy: 0.0425\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0430 - accuracy: 0.1021 - val_loss: 3.0995 - val_accuracy: 0.0425\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0423 - accuracy: 0.1012 - val_loss: 3.0994 - val_accuracy: 0.0425\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0417 - accuracy: 0.1012 - val_loss: 3.0993 - val_accuracy: 0.0425\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0412 - accuracy: 0.1012 - val_loss: 3.0993 - val_accuracy: 0.0425\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0407 - accuracy: 0.1012 - val_loss: 3.0990 - val_accuracy: 0.0425\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0400 - accuracy: 0.1003 - val_loss: 3.0996 - val_accuracy: 0.0425\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0400 - accuracy: 0.1012 - val_loss: 3.1004 - val_accuracy: 0.0377\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 3.0400 - accuracy: 0.1047 - val_loss: 3.1000 - val_accuracy: 0.0377\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0393 - accuracy: 0.1021 - val_loss: 3.0992 - val_accuracy: 0.0425\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0391 - accuracy: 0.1038 - val_loss: 3.0978 - val_accuracy: 0.0425\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0389 - accuracy: 0.1055 - val_loss: 3.0959 - val_accuracy: 0.0425\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0379 - accuracy: 0.1029 - val_loss: 3.0951 - val_accuracy: 0.0425\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0377 - accuracy: 0.1038 - val_loss: 3.0947 - val_accuracy: 0.0425\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0375 - accuracy: 0.1029 - val_loss: 3.0945 - val_accuracy: 0.0425\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 3.0374 - accuracy: 0.1021 - val_loss: 3.0944 - val_accuracy: 0.0472\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 3.0372 - accuracy: 0.1047 - val_loss: 3.0946 - val_accuracy: 0.0425\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 3.0373 - accuracy: 0.1021 - val_loss: 3.0947 - val_accuracy: 0.0472\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0366 - accuracy: 0.1029 - val_loss: 3.0949 - val_accuracy: 0.0472\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0360 - accuracy: 0.1003 - val_loss: 3.0960 - val_accuracy: 0.0472\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0363 - accuracy: 0.1003 - val_loss: 3.0967 - val_accuracy: 0.0472\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0359 - accuracy: 0.1003 - val_loss: 3.0966 - val_accuracy: 0.0472\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0353 - accuracy: 0.1012 - val_loss: 3.0966 - val_accuracy: 0.0472\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0350 - accuracy: 0.1029 - val_loss: 3.0962 - val_accuracy: 0.0425\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0348 - accuracy: 0.1029 - val_loss: 3.0968 - val_accuracy: 0.0472\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.0349 - accuracy: 0.1055 - val_loss: 3.0970 - val_accuracy: 0.0472\n",
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5.3819 - accuracy: 0.0062 - val_loss: 4.8873 - val_accuracy: 0.0539\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 4.8816 - accuracy: 0.0598 - val_loss: 4.5206 - val_accuracy: 0.0588\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 4.5040 - accuracy: 0.0641 - val_loss: 4.2290 - val_accuracy: 0.0490\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 4.2024 - accuracy: 0.0641 - val_loss: 3.9936 - val_accuracy: 0.0539\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.9589 - accuracy: 0.0747 - val_loss: 3.7964 - val_accuracy: 0.0490\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.7546 - accuracy: 0.0879 - val_loss: 3.6307 - val_accuracy: 0.0294\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.5852 - accuracy: 0.0861 - val_loss: 3.5032 - val_accuracy: 0.0392\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.4558 - accuracy: 0.0861 - val_loss: 3.4204 - val_accuracy: 0.0539\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.3724 - accuracy: 0.0791 - val_loss: 3.3766 - val_accuracy: 0.0686\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.3296 - accuracy: 0.0756 - val_loss: 3.3570 - val_accuracy: 0.0735\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.3117 - accuracy: 0.0800 - val_loss: 3.3447 - val_accuracy: 0.0588\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.3014 - accuracy: 0.0967 - val_loss: 3.3259 - val_accuracy: 0.0588\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.2857 - accuracy: 0.0958 - val_loss: 3.2994 - val_accuracy: 0.0588\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2633 - accuracy: 0.0870 - val_loss: 3.2725 - val_accuracy: 0.0588\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.2408 - accuracy: 0.0870 - val_loss: 3.2536 - val_accuracy: 0.0588\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.2254 - accuracy: 0.0870 - val_loss: 3.2432 - val_accuracy: 0.0588\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.2161 - accuracy: 0.0870 - val_loss: 3.2408 - val_accuracy: 0.0539\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.2119 - accuracy: 0.0870 - val_loss: 3.2415 - val_accuracy: 0.0539\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.2083 - accuracy: 0.0914 - val_loss: 3.2418 - val_accuracy: 0.0539\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 3.2032 - accuracy: 0.1028 - val_loss: 3.2385 - val_accuracy: 0.0392\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1947 - accuracy: 0.0993 - val_loss: 3.2336 - val_accuracy: 0.0588\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.1850 - accuracy: 0.0905 - val_loss: 3.2280 - val_accuracy: 0.0490\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1753 - accuracy: 0.0975 - val_loss: 3.2229 - val_accuracy: 0.0686\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1661 - accuracy: 0.0949 - val_loss: 3.2186 - val_accuracy: 0.0637\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1582 - accuracy: 0.0975 - val_loss: 3.2151 - val_accuracy: 0.0686\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1514 - accuracy: 0.0984 - val_loss: 3.2117 - val_accuracy: 0.0686\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1446 - accuracy: 0.0949 - val_loss: 3.2082 - val_accuracy: 0.0637\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.1381 - accuracy: 0.0940 - val_loss: 3.2044 - val_accuracy: 0.0686\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1325 - accuracy: 0.0993 - val_loss: 3.2011 - val_accuracy: 0.0686\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.1283 - accuracy: 0.0993 - val_loss: 3.1974 - val_accuracy: 0.0539\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.1244 - accuracy: 0.0967 - val_loss: 3.1933 - val_accuracy: 0.0539\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 3.1212 - accuracy: 0.1019 - val_loss: 3.1886 - val_accuracy: 0.0490\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1183 - accuracy: 0.1019 - val_loss: 3.1837 - val_accuracy: 0.0490\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.1155 - accuracy: 0.1046 - val_loss: 3.1793 - val_accuracy: 0.0539\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.1132 - accuracy: 0.1011 - val_loss: 3.1753 - val_accuracy: 0.0441\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.1110 - accuracy: 0.1002 - val_loss: 3.1727 - val_accuracy: 0.0441\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 3.1094 - accuracy: 0.1019 - val_loss: 3.1704 - val_accuracy: 0.0343\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 3.1072 - accuracy: 0.0967 - val_loss: 3.1688 - val_accuracy: 0.0294\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 3.1047 - accuracy: 0.0949 - val_loss: 3.1683 - val_accuracy: 0.0392\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.1024 - accuracy: 0.0949 - val_loss: 3.1689 - val_accuracy: 0.0294\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.1010 - accuracy: 0.0967 - val_loss: 3.1692 - val_accuracy: 0.0490\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 3.0996 - accuracy: 0.1046 - val_loss: 3.1690 - val_accuracy: 0.0490\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0982 - accuracy: 0.1037 - val_loss: 3.1678 - val_accuracy: 0.0539\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0963 - accuracy: 0.1037 - val_loss: 3.1663 - val_accuracy: 0.0588\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0947 - accuracy: 0.0984 - val_loss: 3.1652 - val_accuracy: 0.0637\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 3.0933 - accuracy: 0.0993 - val_loss: 3.1643 - val_accuracy: 0.0686\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 3.0921 - accuracy: 0.1011 - val_loss: 3.1635 - val_accuracy: 0.0637\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0911 - accuracy: 0.1046 - val_loss: 3.1626 - val_accuracy: 0.0539\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 3.0906 - accuracy: 0.1090 - val_loss: 3.1605 - val_accuracy: 0.0441\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 3.0898 - accuracy: 0.1116 - val_loss: 3.1580 - val_accuracy: 0.0294\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0888 - accuracy: 0.1151 - val_loss: 3.1555 - val_accuracy: 0.0294\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0876 - accuracy: 0.1116 - val_loss: 3.1534 - val_accuracy: 0.0294\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0863 - accuracy: 0.1081 - val_loss: 3.1522 - val_accuracy: 0.0294\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0858 - accuracy: 0.1054 - val_loss: 3.1512 - val_accuracy: 0.0294\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0851 - accuracy: 0.1090 - val_loss: 3.1502 - val_accuracy: 0.0343\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0846 - accuracy: 0.1090 - val_loss: 3.1496 - val_accuracy: 0.0392\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 3.0841 - accuracy: 0.1098 - val_loss: 3.1492 - val_accuracy: 0.0441\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 3.0834 - accuracy: 0.1072 - val_loss: 3.1489 - val_accuracy: 0.0588\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 3.0825 - accuracy: 0.1054 - val_loss: 3.1489 - val_accuracy: 0.0637\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0818 - accuracy: 0.1037 - val_loss: 3.1489 - val_accuracy: 0.0686\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0809 - accuracy: 0.1011 - val_loss: 3.1493 - val_accuracy: 0.0784\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0805 - accuracy: 0.1028 - val_loss: 3.1499 - val_accuracy: 0.0686\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 3.0803 - accuracy: 0.1011 - val_loss: 3.1500 - val_accuracy: 0.0588\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 3.0799 - accuracy: 0.1019 - val_loss: 3.1493 - val_accuracy: 0.0441\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0793 - accuracy: 0.1116 - val_loss: 3.1490 - val_accuracy: 0.0490\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 3.0786 - accuracy: 0.1107 - val_loss: 3.1486 - val_accuracy: 0.0490\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 3.0781 - accuracy: 0.1107 - val_loss: 3.1492 - val_accuracy: 0.0392\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0781 - accuracy: 0.1107 - val_loss: 3.1503 - val_accuracy: 0.0392\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0782 - accuracy: 0.1072 - val_loss: 3.1504 - val_accuracy: 0.0490\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 3.0778 - accuracy: 0.1063 - val_loss: 3.1503 - val_accuracy: 0.0539\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0772 - accuracy: 0.1081 - val_loss: 3.1501 - val_accuracy: 0.0539\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 3.0768 - accuracy: 0.1054 - val_loss: 3.1494 - val_accuracy: 0.0588\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0763 - accuracy: 0.1046 - val_loss: 3.1490 - val_accuracy: 0.0588\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0760 - accuracy: 0.1046 - val_loss: 3.1494 - val_accuracy: 0.0490\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 3.0759 - accuracy: 0.1028 - val_loss: 3.1496 - val_accuracy: 0.0490\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 3.0757 - accuracy: 0.1037 - val_loss: 3.1497 - val_accuracy: 0.0539\n",
      "OOS Log Loss: 3.097120284820966\n"
     ]
    }
   ],
   "source": [
    "n_hidden_layers = study.best_params['n_hidden_layers']\n",
    "\n",
    "hidden_layer_neurons = []\n",
    "l1s = []\n",
    "l2s = []\n",
    "for i in range(n_hidden_layers):\n",
    "    hidden_layer_neurons.append(study.best_params[f\"hidden_layer_{i+1}_neurons\"])\n",
    "    l1s.append(study.best_params[f\"hidden_layer_{i+1}_l1\"])\n",
    "    l2s.append(study.best_params[f\"hidden_layer_{i+1}_l2\"])\n",
    "\n",
    "learning_rate = study.best_params[f\"learning_rate\"]\n",
    "batch_size = study.best_params[f\"batch_size\"]\n",
    "\n",
    "y_oos_list = []\n",
    "y_pred_list = []\n",
    "testing_data = []\n",
    "for X_train, X_val, X_oos, y_train, y_val, y_oos, df_mod_oos in cv_data:\n",
    "    # make sure to build mod in loop to prevent history\n",
    "    mod = build_and_compile_model(X_train.shape[1:], y_train.shape[1], hidden_layer_neurons, l1s, l2s, learning_rate)\n",
    "\n",
    "    mod.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=batch_size,\n",
    "        epochs=500,\n",
    "        callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    y_preds = mod.predict(X_oos, verbose=0)\n",
    "\n",
    "    df_preds = pd.DataFrame(\n",
    "        y_preds,\n",
    "        columns=y.columns\n",
    "    )\n",
    "\n",
    "    testing_data.append(pd.concat((df_mod_oos.reset_index(drop=True), df_preds), axis=1))\n",
    "\n",
    "\n",
    "    y_oos_list.append(y_oos)\n",
    "    y_pred_list.append(y_preds)\n",
    "\n",
    "df_test = pd.concat(testing_data, ignore_index=True)\n",
    "\n",
    "y_oos_concat = np.vstack(y_oos_list)\n",
    "y_pred_concat = np.vstack(y_pred_list)\n",
    "\n",
    "print(f\"OOS Log Loss: {log_loss(y_oos_concat, y_pred_concat)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_distribution(row):\n",
    "    distribution = row[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].astype('float64')/row[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].astype('float64').sum()\n",
    "\n",
    "    return np.random.choice([i for i in range(-4, 56)], p=distribution, size=1_000)\n",
    "\n",
    "# get_random_distribution(df_test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06944444444444445"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_test['Fantasy Points'] < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(22)\n",
    "\n",
    "row = df_test.iloc[1_000]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "random_distribution = get_random_distribution(row)\n",
    "\n",
    "ax = sns.kdeplot(random_distribution, fill=True, bw_adjust=1.0, color='blue', label='Projected Fantasy Points Distribution')\n",
    "\n",
    "current_limits = ax.get_ylim()\n",
    "\n",
    "plt.vlines(x=row['Fantasy Points'], ymin=0.0, ymax=1.0, colors=['red'], label='Actual Fantasy Points Scored')\n",
    "\n",
    "ax.set_ylim(current_limits)\n",
    "\n",
    "plt.title(f\"{row['Name'].title()} {row['Season']} Week {row['Week']} Projected Fantasy Points Distribution\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.618158848503356"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "root_mean_squared_error(\n",
    "    df_test['Fantasy Points'],\n",
    "    np.dot(np.array([i for i in range(-4, 56)]), df_test[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].transpose()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.332050911573073"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mean_absolute_error(\n",
    "    df_test['Fantasy Points'],\n",
    "    np.dot(np.array([i for i in range(-4, 56)]), df_test[[f\"{i} Fantasy Points\" for i in range(-4, 56)]].transpose()),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How often do players end up in certain percentiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles = [(df_test.iloc[i]['Fantasy Points'] > get_random_distribution(df_test.iloc[i])).mean() for i in range(df_test.shape[0])]\n",
    "\n",
    "len(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(\n",
    "    x=percentiles,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2016.000000\n",
       "mean        0.475555\n",
       "std         0.292919\n",
       "min         0.000000\n",
       "1%          0.000000\n",
       "5%          0.040000\n",
       "10%         0.076500\n",
       "25%         0.225750\n",
       "50%         0.459000\n",
       "75%         0.735250\n",
       "90%         0.892500\n",
       "95%         0.944000\n",
       "99%         0.987000\n",
       "max         0.999000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(percentiles).describe(percentiles=[0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
